{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extreme Video Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import concurrent.futures as multithreading\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video:\n",
    "    \n",
    "    @staticmethod\n",
    "    def compress(\n",
    "        filename, \n",
    "        output_dst = None, \n",
    "        fraction   = 0.01\n",
    "    ):\n",
    "        def get_indices(\n",
    "            height, \n",
    "            width, \n",
    "            fraction\n",
    "        ):\n",
    "            def to_2d(\n",
    "                index\n",
    "            ):\n",
    "                return (index // width, index % width)\n",
    "\n",
    "            samples = np.random.permutation(width * height)[:int(width * height * fraction)]\n",
    "\n",
    "            indices = [to_2d(index) for index in samples]\n",
    "\n",
    "            return tuple(zip(*indices))\n",
    "\n",
    "\n",
    "        def sample_frame(\n",
    "            frame, \n",
    "            fraction\n",
    "        ):\n",
    "            height, width, nb_channels = frame.shape\n",
    "\n",
    "            indices = get_indices(height, width, fraction)\n",
    "\n",
    "            return np.expand_dims(frame[indices], axis=0)\n",
    "\n",
    "\n",
    "        seed = np.array(np.random.randint(0, np.iinfo(np.int32).max))\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        cap = cv2.VideoCapture(filename)\n",
    "        framerate = np.array(cap.get(cv2.cv2.CAP_PROP_FPS))\n",
    "\n",
    "        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        start_time = time.time()\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        dimensions = np.array(frame.shape)\n",
    "\n",
    "        video = sample_frame(frame, fraction)\n",
    "        curr_frame = 1\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            sampled_frame = sample_frame(frame, fraction)\n",
    "\n",
    "            video = np.vstack((video, sampled_frame))\n",
    "\n",
    "            curr_frame += 1\n",
    "            print('Compressing Video: ' + str(int(100 * curr_frame / num_frames)) + \n",
    "                  '%\\tTime Elapsed: ' + str(int(np.floor(time.time() - start_time))) + ' seconds', end='\\r')\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        print('Compressing Video: 100%\\tTime Elapsed: ' + str(int(np.floor(time.time() - start_time))) + ' seconds')\n",
    "\n",
    "        if output_dst is None:\n",
    "            output_dst = '../Results/CompressedVideos/' + filename.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            output_dst, \n",
    "            video=video, \n",
    "            dimensions=dimensions, \n",
    "            framerate=framerate,\n",
    "            seed=seed,\n",
    "            fraction=np.array(fraction)\n",
    "        )\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def psnr(\n",
    "        original, \n",
    "        reconstructed, \n",
    "        color_channels = 'bgr'\n",
    "    ):\n",
    "        \n",
    "        cap_original = cv2.VideoCapture(original)\n",
    "        cap_reconstructed = cv2.VideoCapture(reconstructed)\n",
    "        \n",
    "        num_frames_original = int(cap_original.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        num_frames_reconstructed = int(cap_reconstructed.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        num_frames = min(num_frames_original, num_frames_reconstructed)\n",
    "        \n",
    "        mse_list = []\n",
    "        max_pixel_value = np.iinfo(np.uint8).max\n",
    "        \n",
    "        start_time = time.time()\n",
    "        curr_frame = 0\n",
    "        \n",
    "        while cap_original.isOpened() and cap_reconstructed.isOpened():\n",
    "            ret_original, frame_original = cap_original.read()\n",
    "            ret_reconstructed, frame_reconstructed = cap_reconstructed.read()\n",
    "            \n",
    "            if (not ret_original) or (not ret_reconstructed):\n",
    "                break\n",
    "            \n",
    "            height = frame_original.shape[0]\n",
    "            width = frame_original.shape[1]\n",
    "            frame_mse = 0\n",
    "            \n",
    "            if color_channels == 'bgr':\n",
    "                nb_channels = frame_original.shape[2]\n",
    "                total_squared_error = np.sum(np.square(frame_original.astype(int) - \n",
    "                                                       frame_reconstructed.astype(int)))\n",
    "                frame_mse = total_squared_error / (width * height * nb_channels)\n",
    "            \n",
    "            elif color_channels == 'ycrcb':\n",
    "                frame_original = cv2.cvtColor(frame_original, cv2.COLOR_BGR2YCrCb)\n",
    "                frame_reconstructed = cv2.cvtColor(frame_reconstructed, cv2.COLOR_BGR2YCrCb)\n",
    "                total_squared_error = np.sum(np.square(frame_original[:,:,0].astype(int) - \n",
    "                                                       frame_reconstructed[:,:,0].astype(int)))\n",
    "                frame_mse = total_squared_error / (width * height)\n",
    "            \n",
    "            mse_list.append(frame_mse)\n",
    "            \n",
    "            curr_frame += 1\n",
    "            print('Computing PSNR: ' + str(int(100 * curr_frame / num_frames)) +\n",
    "                  '%\\tTime Elapsed: ' + str(int(np.floor(time.time() - start_time))) + ' seconds', end='\\r')\n",
    "        \n",
    "        mse = np.mean(mse_list)\n",
    "        psnr = 10 * np.log10((max_pixel_value ** 2) / mse)\n",
    "        \n",
    "        print('Computing PSNR: 100%\\tTime Elapsed: ' + str(int(np.floor(time.time() - start_time))) + ' seconds')\n",
    "        \n",
    "        cap_original.release()\n",
    "        cap_reconstructed.release()\n",
    "        \n",
    "        return psnr\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def color_distributions(\n",
    "        filename, \n",
    "        window_width, \n",
    "        color_channels = 'bgr'\n",
    "    ):\n",
    "        alpha = 0.95\n",
    "        window_overlap = 0.5\n",
    "        \n",
    "        uniform = np.ones(np.iinfo(np.uint8).max + 1) / (np.iinfo(np.uint8).max + 1)\n",
    "        \n",
    "        \n",
    "        def intervals(\n",
    "            length\n",
    "        ):\n",
    "            return [slice(x, min(x + window_width, length)) for x in \n",
    "                    range(0, max(1, length - int(window_width * window_overlap)), \n",
    "                          int(window_width * (1 - window_overlap)))]\n",
    "\n",
    "\n",
    "        def window_color_distributions(\n",
    "            window\n",
    "        ):\n",
    "            return np.array([alpha * np.histogram(window[:,channel], \n",
    "                                                  bins=range(np.iinfo(np.uint8).max + 2), \n",
    "                                                  density=True)[0] +\n",
    "                             (1 - alpha) * uniform\n",
    "                             for channel in range(self.nb_channels)]).flatten()\n",
    "\n",
    "        \n",
    "        def preprocess_frame(\n",
    "            frame_index, \n",
    "            windows\n",
    "        ):\n",
    "            augmented_frame = prepare_frame(frame_index)\n",
    "\n",
    "            frame_color_distributions = [\n",
    "                window_color_distributions(\n",
    "                    augmented_frame[window][augmented_frame[window][:,:,-1] == 1][:,:-1]\n",
    "                ) for window in windows\n",
    "            ]\n",
    "\n",
    "            return augmented_frame, frame_color_distributions\n",
    "        \n",
    "        \n",
    "        cap = cv2.VideoCapture(filename)\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        height = frame.shape[0]\n",
    "        width = frame.shape[1]\n",
    "        nb_channels = frame.shape[2]\n",
    "        \n",
    "        windows = [(y, x) for x in intervals(width) for y in intervals(height)]\n",
    "        print(windows)\n",
    "        frames_color_distributions = []\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_color_distributions = [\n",
    "                window_color_distributions(frame[window]) for window in windows\n",
    "            ]\n",
    "            \n",
    "            frames_color_distributions.append(frame_color_distributions)\n",
    "\n",
    "        cap.release()\n",
    "        \n",
    "        return np.array(frames_color_distributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(slice(0, 150, None), slice(0, 150, None)), (slice(75, 225, None), slice(0, 150, None)), (slice(150, 300, None), slice(0, 150, None)), (slice(225, 360, None), slice(0, 150, None)), (slice(0, 150, None), slice(75, 225, None)), (slice(75, 225, None), slice(75, 225, None)), (slice(150, 300, None), slice(75, 225, None)), (slice(225, 360, None), slice(75, 225, None)), (slice(0, 150, None), slice(150, 300, None)), (slice(75, 225, None), slice(150, 300, None)), (slice(150, 300, None), slice(150, 300, None)), (slice(225, 360, None), slice(150, 300, None)), (slice(0, 150, None), slice(225, 375, None)), (slice(75, 225, None), slice(225, 375, None)), (slice(150, 300, None), slice(225, 375, None)), (slice(225, 360, None), slice(225, 375, None)), (slice(0, 150, None), slice(300, 450, None)), (slice(75, 225, None), slice(300, 450, None)), (slice(150, 300, None), slice(300, 450, None)), (slice(225, 360, None), slice(300, 450, None)), (slice(0, 150, None), slice(375, 525, None)), (slice(75, 225, None), slice(375, 525, None)), (slice(150, 300, None), slice(375, 525, None)), (slice(225, 360, None), slice(375, 525, None)), (slice(0, 150, None), slice(450, 600, None)), (slice(75, 225, None), slice(450, 600, None)), (slice(150, 300, None), slice(450, 600, None)), (slice(225, 360, None), slice(450, 600, None)), (slice(0, 150, None), slice(525, 640, None)), (slice(75, 225, None), slice(525, 640, None)), (slice(150, 300, None), slice(525, 640, None)), (slice(225, 360, None), slice(525, 640, None))]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video.color_distributions('Resources/VideoSamples/Seal.mp4', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kernels:\n",
    "    \n",
    "    @staticmethod\n",
    "    def kernel_2d(\n",
    "        kernel_size, \n",
    "        sigma\n",
    "    ):\n",
    "        center = (kernel_size - 1) / 2\n",
    "        kernel = np.fromfunction(\n",
    "            lambda x, y: \n",
    "                np.exp( -0.5 * ((x - center) ** 2 + (y - center) ** 2) / (sigma ** 2)), \n",
    "            (kernel_size, kernel_size), \n",
    "            dtype=float\n",
    "        )\n",
    "        return kernel\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def kernel_3d(\n",
    "        kernel_size, \n",
    "        sigma, \n",
    "        num_kernels, \n",
    "        sigma_time\n",
    "    ):\n",
    "        center = (kernel_size - 1) / 2\n",
    "        kernels = np.fromfunction(\n",
    "            lambda t, x, y: \n",
    "                np.exp( -0.5 * (\n",
    "                                 (((x - center) ** 2 + (y - center) ** 2) / (sigma ** 2)) + \n",
    "                                  ((t ** 2) / (sigma_time ** 2))\n",
    "                               )\n",
    "                ), \n",
    "            (num_kernels, kernel_size, kernel_size), \n",
    "            dtype=float\n",
    "        )\n",
    "        return kernels\n",
    "\n",
    "\n",
    "class CompressedVideo:\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        filename\n",
    "    ):\n",
    "        file_dict = np.load(filename)\n",
    "        \n",
    "        self.filename = filename.split('.npz')[0]\n",
    "        self.height = file_dict['dimensions'][0]\n",
    "        self.width = file_dict['dimensions'][1]\n",
    "        self.nb_channels = file_dict['dimensions'][2]\n",
    "        self.video = file_dict['video']\n",
    "        self.num_frames = self.video.shape[0]\n",
    "        self.framerate = file_dict['framerate']\n",
    "        self.seed = file_dict['seed']\n",
    "        self.fraction = file_dict['fraction']\n",
    "        \n",
    "        # Create indices from seed\n",
    "        def indices_generator():\n",
    "            np.random.seed(self.seed)\n",
    "            for idx in range(self.num_frames):\n",
    "                samples = np.random.permutation(self.width * self.height)[:int(self.width * self.height * self.fraction)]\n",
    "                yield tuple(zip(*[(index // self.width, index % self.width) for index in samples]))\n",
    "        \n",
    "        self.indices = np.array([i for i in indices_generator()])\n",
    "        \n",
    "        \n",
    "        self.defaults = {}\n",
    "        self.defaults['sigma']           = np.sqrt((self.height * self.width) / \n",
    "                                                   (self.video[0].shape[0] * np.pi))\n",
    "        self.defaults['kernel_size']     = 2 * (int(0.5 + 3 * self.defaults['sigma']) + 2) + 1\n",
    "        self.defaults['num_time_frames'] = 15\n",
    "        self.defaults['output_dst']      = self.filename + '_reconstructed.mov'\n",
    "        self.defaults['multithreaded']   = True\n",
    "        self.defaults['alpha']           = 0.95\n",
    "        self.defaults['beta']            = 80\n",
    "        self.defaults['window_width']    = 150\n",
    "        self.defaults['window_overlap']  = 0.5\n",
    "    \n",
    "    \n",
    "    def reconstruct(\n",
    "        self, \n",
    "        algorithm      = 'efan2d', \n",
    "        color_channels = 'bgr', \n",
    "        verbose        = False, \n",
    "        filter_type    = 'normal',\n",
    "        avg_method     = 'normal',\n",
    "        kernel_type    = 'constant',\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        TODO complete description\n",
    "        \"\"\"\n",
    "        \n",
    "        if 'kernel_size' in kwargs:\n",
    "            kernel_size = kwargs['kernel_size']\n",
    "        else:\n",
    "            kernel_size = self.defaults['kernel_size']\n",
    "        \n",
    "        if 'sigma' in kwargs:\n",
    "            sigma = kwargs['sigma']\n",
    "        else:\n",
    "            sigma = self.defaults['sigma']\n",
    "        \n",
    "        if 'num_time_frames' in kwargs:\n",
    "            num_time_frames = kwargs['num_time_frames']\n",
    "        else:\n",
    "            num_time_frames = self.defaults['num_time_frames']\n",
    "        \n",
    "        if 'output_dst' in kwargs:\n",
    "            output_dst = kwargs['output_dst']\n",
    "        else:\n",
    "            output_dst = self.defaults['output_dst']\n",
    "        \n",
    "        if 'multithreaded' in kwargs:\n",
    "            multithreaded = kwargs['multithreaded']\n",
    "        else:\n",
    "            multithreaded = self.defaults['multithreaded']\n",
    "        \n",
    "        if 'alpha' in kwargs:\n",
    "            alpha = kwargs['alpha']\n",
    "        else:\n",
    "            alpha = self.defaults['alpha']\n",
    "        \n",
    "        if 'beta' in kwargs:\n",
    "            beta = kwargs['beta']\n",
    "        else:\n",
    "            beta = self.defaults['beta']\n",
    "        \n",
    "        if 'window_width' in kwargs:\n",
    "            window_width = kwargs['window_width']\n",
    "        else:\n",
    "            window_width = self.defaults['window_width']\n",
    "        \n",
    "        if 'window_overlap' in kwargs:\n",
    "            window_overlap = kwargs['window_overlap']\n",
    "        else:\n",
    "            window_overlap = self.defaults['window_overlap']\n",
    "        \n",
    "        \n",
    "        def display_progress(\n",
    "            frame_index, \n",
    "            start_time, \n",
    "            filter_times, \n",
    "            complete = False\n",
    "        ):\n",
    "            if verbose:\n",
    "                print('Reconstructing Video: ' + str(int(100 * frame_index / self.num_frames)) + '% ' + \n",
    "                      '\\tTime Elapsed: ' + str(np.round(time.time() - start_time, 2)) + ' seconds ' +\n",
    "                      '\\tFilter Time: '  + str(np.round(np.sum(filter_times), 2)) + ' seconds', end='\\r')\n",
    "\n",
    "                if complete:\n",
    "                    print('')\n",
    "        \n",
    "        \n",
    "        def prepare_frame(\n",
    "            frame_index\n",
    "        ):\n",
    "            frame = self.video[frame_index]\n",
    "            indices = self.indices[frame_index]\n",
    "\n",
    "            black_frame = np.zeros((self.height, self.width, self.nb_channels))\n",
    "                \n",
    "            if color_channels == 'ycrcb':\n",
    "                frame = cv2.cvtColor(np.expand_dims(frame, axis=0), cv2.COLOR_BGR2YCrCb)[0]\n",
    "            \n",
    "            black_frame[tuple(indices)] = frame\n",
    "\n",
    "            new_channel = np.zeros((self.height, self.width, 1)) + 1e-10 # To avoid division by zero\n",
    "            new_channel[tuple(indices)] = 1.0\n",
    "\n",
    "            augmented_frame = np.append(black_frame, new_channel, axis=2)\n",
    "            \n",
    "            return augmented_frame\n",
    "        \n",
    "        \n",
    "        def normalize_frame(\n",
    "            frame\n",
    "        ):\n",
    "            for i in range(self.nb_channels):\n",
    "                frame[:,:,i] /= frame[:,:,-1]\n",
    "\n",
    "            reconstructed_frame = (frame[:,:,:-1] + 0.5).astype(np.uint8)\n",
    "            \n",
    "            return reconstructed_frame\n",
    "        \n",
    "        \n",
    "        def efan2d(\n",
    "            output\n",
    "        ):\n",
    "            \"\"\"\n",
    "            EFAN2D Algorithm\n",
    "            \"\"\"\n",
    "            \n",
    "            filter_times = []\n",
    "\n",
    "            def filter_frame(\n",
    "                frame_index, \n",
    "                kernel\n",
    "            ):\n",
    "                augmented_frame = prepare_frame(frame_index)\n",
    "\n",
    "                st = time.time()\n",
    "                filtered = cv2.filter2D(augmented_frame, -1, kernel, \n",
    "                                        borderType=cv2.BORDER_CONSTANT)\n",
    "                filter_times.append(time.time() - st)\n",
    "                \n",
    "                return filtered\n",
    "            \n",
    "            \n",
    "            def reconstruct_frame(\n",
    "                frame_index, \n",
    "                kernel\n",
    "            ):\n",
    "                filtered = filter_frame(frame_index, kernel)\n",
    "                reconstructed_frame = normalize_frame(filtered)\n",
    "                \n",
    "                return reconstructed_frame\n",
    "            \n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            kernel = Kernels.kernel_2d(kernel_size, sigma)\n",
    "            \n",
    "            display_progress(0, start_time, filter_times)\n",
    "            \n",
    "            for frame_index in range(self.num_frames):\n",
    "                reconstructed_frame = reconstruct_frame(frame_index, kernel)\n",
    "                \n",
    "                if color_channels == 'ycrcb':\n",
    "                    reconstructed_frame = cv2.cvtColor(reconstructed_frame, cv2.COLOR_YCrCb2BGR)\n",
    "                \n",
    "                output.write(reconstructed_frame)\n",
    "                display_progress(frame_index, start_time, filter_times)\n",
    "            \n",
    "            display_progress(self.num_frames, start_time, filter_times, complete=True)\n",
    "\n",
    "\n",
    "        def efan3d(\n",
    "            output\n",
    "        ):\n",
    "            \"\"\"\n",
    "            EFAN3D Algorithm\n",
    "            \"\"\"\n",
    "            \n",
    "            num_kernels = (num_time_frames + 1) // 2\n",
    "            sigma_time = (num_kernels - 1) / 6\n",
    "            \n",
    "            filter_times = []\n",
    "            \n",
    "            def filter_frame(\n",
    "                frame_index, \n",
    "                kernels\n",
    "            ):\n",
    "                augmented_frame = prepare_frame(frame_index)\n",
    "\n",
    "                st = time.time()\n",
    "                \n",
    "                if multithreaded:\n",
    "                    filtered_frame = [None for i in range(num_kernels)]\n",
    "\n",
    "                    def apply_kernel(\n",
    "                        kernel_index\n",
    "                    ):\n",
    "                        filtered = cv2.filter2D(augmented_frame, -1, kernels[kernel_index], \n",
    "                                                borderType=cv2.BORDER_CONSTANT)\n",
    "                        filtered_frame[kernel_index] = filtered\n",
    "\n",
    "                    with multithreading.ThreadPoolExecutor(max_workers=num_kernels) as executor:\n",
    "                        executor.map(apply_kernel, range(num_kernels))\n",
    "                \n",
    "                else:\n",
    "                    filtered_frame = []\n",
    "                    for kernel in kernels:\n",
    "                        filtered = cv2.filter2D(augmented_frame, -1, kernel, \n",
    "                                                borderType=cv2.BORDER_CONSTANT)\n",
    "                        filtered_frame.append(filtered)\n",
    "                \n",
    "                filter_times.append(time.time() - st)\n",
    "                \n",
    "                return filtered_frame\n",
    "            \n",
    "            \n",
    "            def reconstruct_frame(\n",
    "                frame_index, \n",
    "                filtered_frames\n",
    "            ):\n",
    "                filtered_sum = np.zeros((self.height, self.width, self.nb_channels + 1))\n",
    "            \n",
    "                nb_past_frames = min(frame_index, num_kernels - 1)\n",
    "                for idx in range(nb_past_frames):\n",
    "                    filtered_sum += filtered_frames[idx][nb_past_frames - idx]\n",
    "\n",
    "                nb_future_frames = min(self.num_frames - frame_index, num_kernels)\n",
    "                for idx in range(nb_future_frames):\n",
    "                    filtered_sum += filtered_frames[min(frame_index, num_kernels - 1) + idx][idx]\n",
    "                \n",
    "                reconstructed_frame = normalize_frame(filtered_sum)\n",
    "                \n",
    "                return reconstructed_frame\n",
    "            \n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            kernels = Kernels.kernel_3d(kernel_size, sigma, num_kernels, sigma_time)\n",
    "            \n",
    "            filtered_frames = []\n",
    "            \n",
    "            display_progress(0, start_time, filter_times)\n",
    "            \n",
    "            for frame_index in range(self.num_frames):\n",
    "                \n",
    "                if frame_index == 0:\n",
    "                    for idx in range(num_kernels):\n",
    "                        filtered_frames.append(filter_frame(idx, kernels))\n",
    "                        \n",
    "                elif frame_index < num_kernels:\n",
    "                    filtered_frames.append(filter_frame((num_kernels - 1) + frame_index, kernels))\n",
    "                    \n",
    "                elif frame_index <= self.num_frames - num_kernels:\n",
    "                    filtered_frames.append(filter_frame((num_kernels - 1) + frame_index, kernels))\n",
    "                    filtered_frames = filtered_frames[1:]\n",
    "                    \n",
    "                else:\n",
    "                    filtered_frames = filtered_frames[1:]\n",
    "                \n",
    "                reconstructed_frame = reconstruct_frame(frame_index, filtered_frames)\n",
    "                \n",
    "                if color_channels == 'ycrcb':\n",
    "                    reconstructed_frame = cv2.cvtColor(reconstructed_frame, cv2.COLOR_YCrCb2BGR)\n",
    "                \n",
    "                output.write(reconstructed_frame)\n",
    "                \n",
    "                display_progress(frame_index, start_time, filter_times)\n",
    "            \n",
    "            display_progress(self.num_frames, start_time, filter_times, complete=True)\n",
    "        \n",
    "        \n",
    "        def adefan(\n",
    "            output\n",
    "        ):\n",
    "            \"\"\"\n",
    "            ADEFAN Algorithm\n",
    "            \"\"\"\n",
    "            \n",
    "            num_kernels = (num_time_frames + 1) // 2\n",
    "            sigma_time = (num_kernels - 1) / 6\n",
    "            uniform = np.ones(np.iinfo(np.uint8).max + 1) / (np.iinfo(np.uint8).max + 1)\n",
    "            \n",
    "            window_kernel = Kernels.kernel_2d(window_width, window_width / 6)\n",
    "            \n",
    "            filter_times = []\n",
    "            \n",
    "            def intervals(\n",
    "                length\n",
    "            ):\n",
    "                return [slice(x, min(x + window_width, length)) for x in \n",
    "                        range(0, max(1, length - int(window_width * window_overlap)), \n",
    "                              int(window_width * (1 - window_overlap)))]\n",
    "            \n",
    "            \n",
    "            def window_color_distributions(\n",
    "                window\n",
    "            ):\n",
    "                return np.array([alpha * np.histogram(window[:,channel], \n",
    "                                                      bins=range(np.iinfo(np.uint8).max + 2), \n",
    "                                                      density=True)[0] +\n",
    "                                 (1 - alpha) * uniform\n",
    "                                 for channel in range(self.nb_channels)]).flatten()\n",
    "            \n",
    "            \n",
    "            def preprocess_frame(\n",
    "                frame_index, \n",
    "                windows\n",
    "            ):\n",
    "                augmented_frame = prepare_frame(frame_index)\n",
    "                \n",
    "                frame_color_distributions = [\n",
    "                    window_color_distributions(\n",
    "                        augmented_frame[window][augmented_frame[window][:,:,-1] == 1][:,:-1]\n",
    "                    ) for window in windows\n",
    "                ]\n",
    "                \n",
    "                return augmented_frame, frame_color_distributions\n",
    "            \n",
    "            \n",
    "            def compute_max_divergence(\n",
    "                frame_index, \n",
    "                frames_color_distributions\n",
    "            ):\n",
    "                curr_frame_index = min(frame_index, num_kernels - 1)\n",
    "                curr_frame_distributions = frames_color_distributions[curr_frame_index]\n",
    "                num_windows = len(curr_frame_distributions)\n",
    "                \n",
    "                max_frame_index = min(curr_frame_index + num_kernels, \n",
    "                                      len(frames_color_distributions))\n",
    "                \n",
    "                future_div_max = np.full(num_windows, -1.0)\n",
    "                \n",
    "                for window_idx in range(num_windows):\n",
    "                    for idx in range(curr_frame_index + 1, max_frame_index):\n",
    "                        div = entropy(curr_frame_distributions[window_idx], \n",
    "                                      frames_color_distributions[idx][window_idx])\n",
    "\n",
    "                        if div < future_div_max[window_idx]:\n",
    "                            break\n",
    "                        else:\n",
    "                            future_div_max[window_idx] = div\n",
    "                \n",
    "                future_div_max[future_div_max == -1] = np.finfo(np.float32).max\n",
    "                \n",
    "                min_frame_index = max(0, curr_frame_index - num_kernels + 1)\n",
    "                \n",
    "                past_div_max = np.full(num_windows, -1.0)\n",
    "                \n",
    "                for window_idx in range(num_windows):\n",
    "                    for idx in range(min_frame_index, curr_frame_index):\n",
    "                        div = entropy(curr_frame_distributions[window_idx],\n",
    "                                      frames_color_distributions[idx][window_idx])\n",
    "\n",
    "                        if div < past_div_max[window_idx]:\n",
    "                            break\n",
    "                        else:\n",
    "                            past_div_max[window_idx] = div\n",
    "                \n",
    "                past_div_max[past_div_max == -1] = np.finfo(np.float32).max\n",
    "                \n",
    "                return past_div_max, future_div_max\n",
    "            \n",
    "            \n",
    "            def div_to_num_frames(\n",
    "                past_div_max, \n",
    "                future_div_max\n",
    "            ):\n",
    "                conversion = lambda div: int(np.ceil(num_kernels / (1 + beta * div))) - 1\n",
    "                \n",
    "                num_past_frames = np.vectorize(conversion)(past_div_max)\n",
    "                num_future_frames = np.vectorize(conversion)(future_div_max)\n",
    "                \n",
    "                return num_past_frames, num_future_frames\n",
    "            \n",
    "            \n",
    "            def normalize_window(\n",
    "                filtered_window\n",
    "            ):\n",
    "                kernel = window_kernel[:filtered_window.shape[0], :filtered_window.shape[1]]\n",
    "                \n",
    "                for i in range(self.nb_channels):\n",
    "                    filtered_window[:,:,i] /= filtered_window[:,:,-1]\n",
    "                    filtered_window[:,:,i] *= kernel\n",
    "                \n",
    "                filtered_window[:,:,-1] = kernel\n",
    "                \n",
    "                return filtered_window\n",
    "            \n",
    "            \n",
    "            def reconstruct_frame_by_window(\n",
    "                frame_index, \n",
    "                augmented_frames, \n",
    "                windows, \n",
    "                num_past_frames, \n",
    "                num_future_frames,\n",
    "                kernel_type = 'constant',\n",
    "                avg_method  = 'gaussian'\n",
    "            ):  \n",
    "                if kernel_type == 'constant':\n",
    "                    kernels = Kernels.kernel_3d(kernel_size, sigma, num_kernels, sigma_time)\n",
    "                \n",
    "                filtered_sum = np.zeros((self.height, self.width, self.nb_channels + 1))\n",
    "                \n",
    "                for window, window_num_past_frames, window_num_future_frames in \\\n",
    "                    zip(windows, num_past_frames, num_future_frames):\n",
    "                    \n",
    "                    st = time.time()\n",
    "                    \n",
    "                    if kernel_type == 'variable':\n",
    "                        kernels = Kernels.kernel_3d(\n",
    "                            kernel_size, \n",
    "                            sigma, \n",
    "                            window_num_past_frames + 1, \n",
    "                            max(window_num_past_frames / 6, 0.01)\n",
    "                        )\n",
    "                    \n",
    "                    curr_frame_idx = min(frame_index, num_kernels - 1)\n",
    "                    first_past_frame_idx = max(curr_frame_idx - window_num_past_frames, 0)\n",
    "                    past_frames = [f for f in reversed(augmented_frames[first_past_frame_idx:curr_frame_idx])]\n",
    "                    past_filtered_windows = [None] * len(past_frames)\n",
    "                    \n",
    "                    if multithreaded:\n",
    "                        def filter_past_frame(\n",
    "                            past_frame_idx\n",
    "                        ):\n",
    "                            filtered_window = cv2.filter2D(past_frames[past_frame_idx][window], -1, \n",
    "                                                           kernels[past_frame_idx + 1], \n",
    "                                                           borderType=cv2.BORDER_CONSTANT)\n",
    "                            past_filtered_windows[past_frame_idx] = filtered_window\n",
    "                        \n",
    "                        with multithreading.ThreadPoolExecutor(max_workers=max(len(past_frames), 1)) as executor:\n",
    "                            executor.map(filter_past_frame, range(len(past_frames)))\n",
    "                        \n",
    "                    else:\n",
    "                        for idx, past_frame in enumerate(past_frames):\n",
    "                            filtered_window = cv2.filter2D(past_frame[window], -1, kernels[idx + 1], \n",
    "                                                           borderType=cv2.BORDER_CONSTANT)\n",
    "                            past_filtered_windows[idx] = filtered_window\n",
    "                    \n",
    "                    if kernel_type == 'variable':\n",
    "                        kernels = Kernels.kernel_3d(\n",
    "                            kernel_size, \n",
    "                            sigma, \n",
    "                            window_num_future_frames + 1, \n",
    "                            max(window_num_future_frames / 6, 0.01)\n",
    "                        )\n",
    "                    \n",
    "                    last_future_frame_idx = min(curr_frame_idx + window_num_future_frames, len(augmented_frames))\n",
    "                    future_frames = augmented_frames[curr_frame_idx:last_future_frame_idx]\n",
    "                    future_filtered_windows = [None] * len(future_frames)\n",
    "                    \n",
    "                    if multithreaded:\n",
    "                        def filter_future_frame(\n",
    "                            future_frame_idx\n",
    "                        ):\n",
    "                            filtered_window = cv2.filter2D(future_frames[future_frame_idx][window], -1, \n",
    "                                                           kernels[future_frame_idx], \n",
    "                                                           borderType=cv2.BORDER_CONSTANT)\n",
    "                            future_filtered_windows[future_frame_idx] = filtered_window\n",
    "                        \n",
    "                        with multithreading.ThreadPoolExecutor(max_workers=max(len(future_frames), 1)) as executor:\n",
    "                            executor.map(filter_future_frame, range(len(future_frames)))\n",
    "                        \n",
    "                    else:\n",
    "                        for idx, future_frame in enumerate(future_frames):\n",
    "                            filtered_window = cv2.filter2D(future_frame[window], -1, kernels[idx], \n",
    "                                                           borderType=cv2.BORDER_CONSTANT)\n",
    "                            future_filtered_windows[idx] = filtered_window\n",
    "                    \n",
    "                    filter_times.append(time.time() - st)\n",
    "                    \n",
    "                    filtered_sum_window = np.sum(past_filtered_windows, axis=0) + \\\n",
    "                                          np.sum(future_filtered_windows, axis=0)\n",
    "                    \n",
    "                    if avg_method == 'gaussian':\n",
    "                        filtered_sum_window = normalize_window(filtered_sum_window)\n",
    "                    \n",
    "                    filtered_sum[window] += filtered_sum_window\n",
    "                \n",
    "                filtered_frame = normalize_frame(filtered_sum)\n",
    "                    \n",
    "                return filtered_frame\n",
    "            \n",
    "            \n",
    "            def reconstruct_frame(\n",
    "                frame_index, \n",
    "                augmented_frames, \n",
    "                windows, \n",
    "                num_past_frames, \n",
    "                num_future_frames,\n",
    "                kernel_type = 'constant',\n",
    "                avg_method  = 'gaussian'\n",
    "            ):\n",
    "                kernels = Kernels.kernel_3d(kernel_size, sigma, num_kernels, sigma_time)\n",
    "                \n",
    "                filtered_sum = np.zeros((self.height, self.width, self.nb_channels + 1))\n",
    "                \n",
    "                max_num_past_frames = max(num_past_frames)\n",
    "                max_num_future_frames = max(num_future_frames)\n",
    "                \n",
    "                curr_frame_idx = min(frame_index, num_kernels - 1)\n",
    "                \n",
    "                st = time.time()\n",
    "                \n",
    "                first_past_frame_idx = max(curr_frame_idx - max_num_past_frames, 0)\n",
    "                filtered_past_frames = [None for i in range(curr_frame_idx - first_past_frame_idx)]\n",
    "                past_frames = [f for f in reversed(augmented_frames[first_past_frame_idx:curr_frame_idx])]\n",
    "                \n",
    "                if multithreaded:\n",
    "                    def filter_past_frame(\n",
    "                        past_frame_idx\n",
    "                    ):\n",
    "                        filtered = cv2.filter2D(past_frames[past_frame_idx], -1, \n",
    "                                                kernels[past_frame_idx + 1], \n",
    "                                                borderType=cv2.BORDER_CONSTANT)\n",
    "                        filtered_past_frames[past_frame_idx] = filtered\n",
    "                    \n",
    "                    with multithreading.ThreadPoolExecutor(max_workers=max(max_num_past_frames, 1)) as executor:\n",
    "                        executor.map(filter_past_frame, range(len(past_frames)))\n",
    "                                     \n",
    "                else:\n",
    "                    for idx, past_frame in enumerate(past_frames):\n",
    "                        filtered = cv2.filter2D(past_frame, -1, kernels[idx + 1], \n",
    "                                                borderType=cv2.BORDER_CONSTANT)\n",
    "                        filtered_past_frames[idx] = filtered\n",
    "                \n",
    "                last_future_frame_idx = min(curr_frame_idx + max_num_future_frames, len(augmented_frames) - 1)\n",
    "                filtered_future_frames = [None for i in range(last_future_frame_idx - curr_frame_idx + 1)]\n",
    "                future_frames = augmented_frames[curr_frame_idx:last_future_frame_idx + 1]\n",
    "                \n",
    "                if multithreaded:\n",
    "                    def filter_future_frame(\n",
    "                        future_frame_idx\n",
    "                    ):\n",
    "                        filtered = cv2.filter2D(future_frames[future_frame_idx], -1, \n",
    "                                                kernels[future_frame_idx], \n",
    "                                                borderType=cv2.BORDER_CONSTANT)\n",
    "                        filtered_future_frames[future_frame_idx] = filtered\n",
    "                    \n",
    "                    with multithreading.ThreadPoolExecutor(max_workers=max(max_num_future_frames, 1)) as executor:\n",
    "                        executor.map(filter_future_frame, range(len(future_frames)))\n",
    "                \n",
    "                else:\n",
    "                    for idx, future_frame in enumerate(future_frames):\n",
    "                        filtered = cv2.filter2D(future_frame, -1, kernels[idx], \n",
    "                                                borderType=cv2.BORDER_CONSTANT)\n",
    "                        filtered_future_frames[idx] = filtered\n",
    "                \n",
    "                filter_times.append(time.time() - st)\n",
    "                \n",
    "                for window, window_num_past_frames, window_num_future_frames in \\\n",
    "                    zip(windows, num_past_frames, num_future_frames):\n",
    "                    \n",
    "                    filtered_sum_window = np.zeros((window[0].stop - window[0].start, \n",
    "                                                    window[1].stop - window[1].start,\n",
    "                                                    self.nb_channels + 1))\n",
    "                    \n",
    "                    for past_frame in filtered_past_frames[:window_num_past_frames]:\n",
    "                        filtered_sum_window += past_frame[window]\n",
    "                    \n",
    "                    for future_frame in filtered_future_frames[:window_num_future_frames + 1]:\n",
    "                        filtered_sum_window += future_frame[window]\n",
    "                    \n",
    "                    if avg_method == 'gaussian':\n",
    "                        filtered_sum_window = normalize_window(filtered_sum_window)\n",
    "                    \n",
    "                    filtered_sum[window] += filtered_sum_window\n",
    "                \n",
    "                filtered_frame = normalize_frame(filtered_sum)\n",
    "                    \n",
    "                return filtered_frame\n",
    "            \n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            windows = [(y, x) for x in intervals(self.width) for y in intervals(self.height)]\n",
    "            augmented_frames = []\n",
    "            frames_color_distributions = []\n",
    "            \n",
    "            for frame_index in  range(self.num_frames):\n",
    "                \n",
    "                if frame_index == 0:\n",
    "                    for idx in range(num_kernels):\n",
    "                        augmented_frame, frame_color_distributions = preprocess_frame(idx, windows)\n",
    "                        \n",
    "                        augmented_frames.append(augmented_frame)\n",
    "                        frames_color_distributions.append(frame_color_distributions)\n",
    "                \n",
    "                elif frame_index < num_kernels:\n",
    "                    augmented_frame, frame_color_distributions = \\\n",
    "                        preprocess_frame((num_kernels - 1) + frame_index, windows)\n",
    "                    \n",
    "                    augmented_frames.append(augmented_frame)\n",
    "                    frames_color_distributions.append(frame_color_distributions)\n",
    "                    \n",
    "                elif frame_index <= self.num_frames - num_kernels:\n",
    "                    augmented_frame, frame_color_distributions = \\\n",
    "                        preprocess_frame((num_kernels - 1) + frame_index, windows)\n",
    "                    \n",
    "                    augmented_frames.append(augmented_frame)\n",
    "                    frames_color_distributions.append(frame_color_distributions)\n",
    "                    \n",
    "                    augmented_frames           = augmented_frames[1:]\n",
    "                    frames_color_distributions = frames_color_distributions[1:]\n",
    "                    \n",
    "                else:\n",
    "                    augmented_frames           = augmented_frames[1:]\n",
    "                    frames_color_distributions = frames_color_distributions[1:]\n",
    "                \n",
    "                past_div_max, future_div_max = \\\n",
    "                    compute_max_divergence(frame_index, frames_color_distributions)\n",
    "                \n",
    "                num_past_frames, num_future_frames = \\\n",
    "                    div_to_num_frames(past_div_max, future_div_max)\n",
    "                \n",
    "                if filter_type == 'window':\n",
    "                    reconstructed_frame = reconstruct_frame_by_window(\n",
    "                                            frame_index, \n",
    "                                            augmented_frames, \n",
    "                                            windows, \n",
    "                                            num_past_frames, \n",
    "                                            num_future_frames,\n",
    "                                            kernel_type=kernel_type,\n",
    "                                            avg_method=avg_method\n",
    "                                          )\n",
    "                else:\n",
    "                    reconstructed_frame = reconstruct_frame(\n",
    "                                            frame_index, \n",
    "                                            augmented_frames, \n",
    "                                            windows, \n",
    "                                            num_past_frames, \n",
    "                                            num_future_frames,\n",
    "                                            avg_method=avg_method\n",
    "                                          )\n",
    "                \n",
    "                if color_channels == 'ycrcb':\n",
    "                    reconstructed_frame = cv2.cvtColor(reconstructed_frame, cv2.COLOR_YCrCb2BGR)\n",
    "                \n",
    "                output.write(reconstructed_frame)\n",
    "                \n",
    "                display_progress(frame_index, start_time, filter_times)\n",
    "            display_progress(self.num_frames, start_time, filter_times, complete=True)\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            #############################################\n",
    "        \n",
    "        \n",
    "        output = cv2.VideoWriter(\n",
    "                    output_dst, \n",
    "                    cv2.VideoWriter_fourcc('M','J','P','G'), \n",
    "                    self.framerate, \n",
    "                    (self.width, self.height)\n",
    "                 )\n",
    "        \n",
    "        if algorithm == 'efan2d':\n",
    "            efan2d(output)\n",
    "        elif algorithm == 'efan3d':\n",
    "            efan3d(output)\n",
    "        elif algorithm == 'adefan':\n",
    "            adefan(output)\n",
    "        \n",
    "        output.release()\n",
    "    \n",
    "    \n",
    "    def get_color_distributions(\n",
    "        self, \n",
    "        window_width, \n",
    "        color_channels = 'bgr'\n",
    "    ):\n",
    "        window_overlap = self.defaults['window_overlap']\n",
    "        alpha = self.defaults['alpha']\n",
    "        \n",
    "        uniform = np.ones(np.iinfo(np.uint8).max + 1) / (np.iinfo(np.uint8).max + 1)\n",
    "\n",
    "        def prepare_frame(\n",
    "            frame_index\n",
    "        ):\n",
    "            frame = self.video[frame_index]\n",
    "            indices = self.indices[frame_index]\n",
    "\n",
    "            black_frame = np.zeros((self.height, self.width, self.nb_channels))\n",
    "                \n",
    "            if color_channels == 'ycrcb':\n",
    "                frame = cv2.cvtColor(np.expand_dims(frame, axis=0), cv2.COLOR_BGR2YCrCb)[0]\n",
    "            \n",
    "            black_frame[tuple(indices)] = frame\n",
    "\n",
    "            new_channel = np.zeros((self.height, self.width, 1)) + 1e-10 # To avoid division by zero\n",
    "            new_channel[tuple(indices)] = 1.0\n",
    "\n",
    "            augmented_frame = np.append(black_frame, new_channel, axis=2)\n",
    "            \n",
    "            return augmented_frame\n",
    "        \n",
    "        \n",
    "        def intervals(\n",
    "            length\n",
    "        ):\n",
    "            return [slice(x, min(x + window_width, length)) for x in \n",
    "                    range(0, max(1, length - int(window_width * window_overlap)), \n",
    "                          int(window_width * (1 - window_overlap)))]\n",
    "\n",
    "\n",
    "        def window_color_distributions(\n",
    "            window\n",
    "        ):\n",
    "            return np.array([alpha * np.histogram(window[:,channel], \n",
    "                                                  bins=range(np.iinfo(np.uint8).max + 2), \n",
    "                                                  density=True)[0] +\n",
    "                             (1 - alpha) * uniform\n",
    "                             for channel in range(self.nb_channels)]).flatten()\n",
    "\n",
    "        \n",
    "        def preprocess_frame(\n",
    "            frame_index, \n",
    "            windows\n",
    "        ):\n",
    "            augmented_frame = prepare_frame(frame_index)\n",
    "\n",
    "            frame_color_distributions = [\n",
    "                window_color_distributions(\n",
    "                    augmented_frame[window][augmented_frame[window][:,:,-1] == 1][:,:-1]\n",
    "                ) for window in windows\n",
    "            ]\n",
    "\n",
    "            return augmented_frame, frame_color_distributions\n",
    "        \n",
    "        \n",
    "        windows = [(y, x) for x in intervals(self.width) for y in intervals(self.height)]\n",
    "        frames_color_distributions = []\n",
    "        \n",
    "        for frame_index in  range(self.num_frames):\n",
    "            \n",
    "            _, frame_color_distributions = preprocess_frame(frame_index, windows)\n",
    "            frames_color_distributions.append(frame_color_distributions)\n",
    "        \n",
    "        return np.array(frames_color_distributions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seal = CompressedVideo('../Results/CompressedVideos/Seal.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fcd = seal.get_color_distributions(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245, 32, 768)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fcd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 144.0 seconds \tFilter Time: 120.64 seconds\n"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='adefan', output_dst='../Results/seal_adefan.mov', verbose=True, num_time_frames=199, beta = 20, \n",
    "                 multithreaded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 83.42 seconds \tFilter Time: 55.26 seconds\n"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='adefan', output_dst='../Results/seal_adefan.mov', verbose=True, num_time_frames=199, beta = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 291.49 seconds \tFilter Time: 253.2 seconds\n"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='adefan', output_dst='../Results/seal_adefan_n.mov', \n",
    "                 avg_method='gaussian', verbose=True, num_time_frames=199, beta = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 161.34 seconds \tFilter Time: 122.27 seconds\n"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='adefan', output_dst='../Results/seal_adefan_w.mov', \n",
    "                 filter_type='window', verbose=True, num_time_frames=199, beta = 20, \n",
    "                 multithreaded=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 104.37 seconds \tFilter Time: 64.76 seconds\n"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='adefan', output_dst='../Results/seal_adefan_w.mov', \n",
    "                 filter_type='window', verbose=True, num_time_frames=199, beta = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 316.4 seconds \tFilter Time: 290.38 seconds\n"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='adefan', output_dst='../Results/seal_adefan_nw.mov', \n",
    "                 filter_type='window', avg_method='gaussian', verbose=True, num_time_frames=199, beta = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seal.reconstruct(algorithm='adefan', output_dst='../Results/seal_adefan_nwv.mov', \n",
    "                 filter_type='window', avg_method='gaussian', kernel_type='variable', \n",
    "                 verbose=True, num_time_frames=199, beta = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.161020460662808"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video.psnr('Resources/VideoSamples/Seal.mp4', '../Results/seal_adefan.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.76751316748957"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video.psnr('Resources/VideoSamples/Seal.mp4', '../Results/seal_adefan_n.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "23.202262204205837"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video.psnr('Resources/VideoSamples/Seal.mp4', '../Results/seal_adefan_w.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22.826029662014015"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video.psnr('Resources/VideoSamples/Seal.mp4', '../Results/seal_adefan_nw.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video.psnr('Resources/VideoSamples/Seal.mp4', '../Results/seal_adefan_nwv.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation:\n",
    "    \n",
    "    resources_folder = '../Resources/Videos/'\n",
    "    compressed_folder = '../Results/CompressedVideos/'\n",
    "    reconstructed_folder = '../Results/ReconstructedVideos/'\n",
    "    \n",
    "    @staticmethod\n",
    "    def compress_videos(\n",
    "        motion = 'both'\n",
    "    ):\n",
    "        def compress_folder_content(\n",
    "            folder\n",
    "        ):\n",
    "            suffix = folder + '/'\n",
    "            in_folder = Validation.resources_folder + suffix\n",
    "            out_folder = Validation.compressed_folder + suffix\n",
    "            \n",
    "            for video in os.listdir(in_folder):\n",
    "                video_name = video.split('.')[0]\n",
    "                Video.compress(in_folder + video, out_folder + video_name)\n",
    "        \n",
    "        if motion == 'absent' or motion == 'both':\n",
    "            compress_folder_content('MotionAbsent')\n",
    "        \n",
    "        if motion == 'present' or motion == 'both':\n",
    "            compress_folder_content('MotionPresent')\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def reconstruct_videos(\n",
    "        algorithm      = 'efan2d', \n",
    "        motion         = 'both', \n",
    "        extension      = '.mov', \n",
    "        color_channels = 'bgr'\n",
    "    ):\n",
    "        def reconstruct_folder_content(\n",
    "            folder\n",
    "        ):\n",
    "            suffix = folder + '/'\n",
    "            algorithm_folder = algorithm.upper() + '/'\n",
    "            in_folder = Validation.compressed_folder + suffix\n",
    "            out_folder = Validation.reconstructed_folder + algorithm_folder + suffix\n",
    "            \n",
    "            for video in os.listdir(in_folder):\n",
    "                video_name = video.split('.')[0]\n",
    "                out_filename = video_name + extension\n",
    "                compressed_video = CompressedVideo(in_folder + video)\n",
    "                compressed_video.reconstruct(algorithm=algorithm, \n",
    "                                             output_dst=out_folder+out_filename, \n",
    "                                             color_channels=color_channels)\n",
    "        \n",
    "        if motion == 'absent' or motion == 'both':\n",
    "            reconstruct_folder_content('MotionAbsent')\n",
    "\n",
    "        if motion == 'present' or motion == 'both':\n",
    "            reconstruct_folder_content('MotionPresent')\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_mean_psnr(\n",
    "        algorithm      = 'efan2d', \n",
    "        motion         = 'absent', \n",
    "        color_channels = 'bgr'\n",
    "    ):\n",
    "        def compute_folder_mean_psnr(\n",
    "            folder\n",
    "        ):\n",
    "            psnr_list = []\n",
    "            \n",
    "            suffix = folder + '/'\n",
    "            original_folder = Validation.resources_folder + suffix\n",
    "            algorithm_folder = algorithm.upper() + '/'\n",
    "            reconstructed_folder = Validation.reconstructed_folder + algorithm_folder + suffix\n",
    "            \n",
    "            for original, reconstructed in zip(os.listdir(original_folder), os.listdir(reconstructed_folder)):\n",
    "                psnr = Video.psnr(original_folder + original, \n",
    "                                  reconstructed_folder + reconstructed, \n",
    "                                  color_channels=color_channels)\n",
    "                psnr_list.append(psnr)\n",
    "            \n",
    "            return np.mean(psnr_list)\n",
    "        \n",
    "        if motion == 'absent':\n",
    "            return compute_folder_mean_psnr('MotionAbsent')\n",
    "        \n",
    "        if motion == 'present':\n",
    "            return compute_folder_mean_psnr('MotionPresent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n"
     ]
    }
   ],
   "source": [
    "Video.compress('Resources/VideoSamples/Seal.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seal = CompressedVideo('../Results/CompressedVideos/Seal.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 8 seconds \tFilter Time: 4 seconds\n"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='efan2d', color_channels='ycrcb', output_dst='../Results/seal_ef2.mov', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 22 seconds \tFilter Time: 13 seconds\r"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='efan3d', multithreaded=True, output_dst='../Results/seal_ef3.mov', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 50 seconds \tFilter Time: 41 seconds\r"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='efan3d', multithreaded=False, output_dst='../Results/seal_ef3singlethreaded.mov', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using smaller resolutions seems much more reasonnable given the computational costs of hd videos.\n",
    "Using multithreading for EFAN3D leads to a speedup of a factor 2 in runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21.823762138725613"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video.psnr('Resources/VideoSamples/Seal.mp4', '../Results/seal_ef2.mov', color_channels='ycrcb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing Video: 100%\tTime Elapsed: 4 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 0 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 4 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 0 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 0 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 5 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n"
     ]
    }
   ],
   "source": [
    "Validation.compress_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 27 seconds \tFilter Time: 15 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 3 seconds \tFilter Time: 2 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 8 seconds \tFilter Time: 4 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 26 seconds \tFilter Time: 14 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 11 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 5 seconds \tFilter Time: 2 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 13 seconds \tFilter Time: 7 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 6 seconds \tFilter Time: 3 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 12 seconds \tFilter Time: 7 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 23 seconds \tFilter Time: 13 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 20 seconds \tFilter Time: 11 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 13 seconds \tFilter Time: 7 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 18 seconds \tFilter Time: 10 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 13 seconds \tFilter Time: 7 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 12 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 11 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 15 seconds \tFilter Time: 8 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 17 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 10 seconds \tFilter Time: 5 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 12 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 6 seconds \tFilter Time: 3 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 18 seconds \tFilter Time: 10 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 17 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 11 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 13 seconds \tFilter Time: 7 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 15 seconds \tFilter Time: 8 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 32 seconds \tFilter Time: 18 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 7 seconds \tFilter Time: 4 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 23 seconds \tFilter Time: 13 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 11 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 19 seconds \tFilter Time: 11 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 12 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 11 seconds \tFilter Time: 6 seconds\n"
     ]
    }
   ],
   "source": [
    "Validation.reconstruct_videos(algorithm='efan2d', color_channels='ycrcb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 3 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 3 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.222866647707434"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation.compute_mean_psnr(motion='absent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 3 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.575506557571156"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation.compute_mean_psnr(motion='present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.43480608669383"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation.compute_mean_psnr(motion='absent', color_channels='ycrcb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.00315016637109"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation.compute_mean_psnr(motion='present', color_channels='ycrcb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive python operations / array indexing: 29.6 hours\n",
      "Numpy (C) operations / array indexing: 9.6 minutes\n",
      "Numpy speedup: 185.0 times faster\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "##### Optimization Benchmark #####\n",
    "##################################\n",
    "\n",
    "height = 720\n",
    "width = 1280\n",
    "num_channels = 3\n",
    "length = 38 #seconds\n",
    "framerate = 24\n",
    "num_frames = length * framerate\n",
    "anchor_x = 400\n",
    "anchor_y = 400\n",
    "num_rand_pixels = (height * width) // 100\n",
    "\n",
    "kernel_size = 71\n",
    "kernel = Kernels.kernel_2d(kernel_size, 20)\n",
    "r = (kernel_size - 1) // 2\n",
    "\n",
    "###########################\n",
    "##### Naive Operation #####\n",
    "###########################\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "kernel_dict = {}\n",
    "for i in range(256):\n",
    "    kernel_dict[i] = kernel * i\n",
    "\n",
    "filtered = np.zeros((height, width, num_channels + 1));\n",
    "\n",
    "for idx in range(num_rand_pixels // 100):\n",
    "    k = kernel_dict[np.random.randint(0,256)]\n",
    "    for c in range(num_channels + 1):\n",
    "        for y in range(kernel_size):\n",
    "            for x in range(kernel_size):\n",
    "                filtered[anchor_x-r+y,anchor_y-r+x,c] += k[x,y]\n",
    "tot_time_naive = (time.time() - st) * num_frames * 100\n",
    "print('Naive python operations / array indexing:', np.around(tot_time_naive / 3600, 1), 'hours')\n",
    "\n",
    "###########################\n",
    "##### Numpy Optimized #####\n",
    "###########################\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "filtered = filtered = np.zeros((height, width, num_channels + 1));\n",
    "\n",
    "kernel_dict = {}\n",
    "for i in range(256):\n",
    "    kernel_dict[i] = kernel * i\n",
    "\n",
    "for i in range(num_rand_pixels):\n",
    "    for c in range(num_channels + 1):\n",
    "        filtered[anchor_y-r:anchor_y+r+1, anchor_x-r:anchor_x+r+1, c] += kernel_dict[np.random.randint(0,256)]\n",
    "\n",
    "tot_time_numpy = (time.time() - st) * num_frames\n",
    "print('Numpy (C) operations / array indexing:', np.around(tot_time_numpy / 60, 1), 'minutes')\n",
    "print('Numpy speedup:', np.around(tot_time_naive / tot_time_numpy, 1), 'times faster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The equivalent of the MATLAB / C++ implementation would take over 29 hours to reconstruct the video using python operations and almost 10 minutes using numpy operations. Since numpy is already written in C there isn't much more to do to speed up the additions / multiplications / array indexing. Even using numpy this is still more than 4 times slower than using opencv to interpolate the value of each pixel (Probably because of the time gained by using filter2D which uses the FFT algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time elapsed 0.05006265640258789 seconds\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "##### MATLAB / Python comparison #####\n",
    "######################################\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "frame = cv2.imread('Resources/ImageComparison/lena.png')\n",
    "width = frame.shape[1]\n",
    "height = frame.shape[0]\n",
    "nb_channels = frame.shape[2]\n",
    "\n",
    "randvec = sio.loadmat('Resources/ImageComparison/randvec.mat')['randind'][0] - 1 # MATLAB indexing starts at 1\n",
    "\n",
    "st = time.time() # Start counting time\n",
    "\n",
    "indices = [(index % height, index // height) for index in randvec] # MATLAB is column major so we convert to row major\n",
    "indices = tuple(zip(*indices))\n",
    "\n",
    "black_frame = np.zeros((height, width, nb_channels))\n",
    "black_frame[indices] = frame[indices]\n",
    "\n",
    "new_channel = np.zeros((height, width, 1)) + 1e-10 # To avoid division by zero\n",
    "new_channel[indices] = 1.0\n",
    "\n",
    "augmented_frame = np.append(black_frame, new_channel, axis=2)\n",
    "\n",
    "sigma = np.sqrt((height * width) / (len(indices[0]) * np.pi))\n",
    "kernel_size = 2 * (int(0.5 + 3 * sigma) + 2) + 1\n",
    "\n",
    "kernel = Kernels.kernel_2d(kernel_size, sigma)\n",
    "\n",
    "filtered = cv2.filter2D(augmented_frame, -1, kernel, borderType=cv2.BORDER_CONSTANT)\n",
    "for i in range(nb_channels):\n",
    "    filtered[:,:,i] /= filtered[:,:,-1]\n",
    "reconstructed_frame = (filtered[:,:,:-1] + 0.5).astype(np.uint8)\n",
    "\n",
    "print('Total time elapsed', time.time() - st, 'seconds')\n",
    "\n",
    "cv2.imwrite('Resources/ImageComparison/lena_python.png', reconstructed_frame);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method takes the same amount of time as the MATLAB / C++ implementation to reconstruct the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different channel values: 2\n"
     ]
    }
   ],
   "source": [
    "lena_matlab = cv2.imread('Resources/ImageComparison/lena_matlab.png')\n",
    "lena_python = cv2.imread('Resources/ImageComparison/lena_python.png')\n",
    "\n",
    "print('Number of different channel values:', np.count_nonzero(lena_matlab - lena_python))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 6 channel values differ between the two images so the methods are equivalent (those values are probably because of different rounding / precision between python and C++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATLAB MSE: 461.09148534138996 \n",
      "Python MSE: 461.0914599100749\n",
      "MATLAB PSNR: 21.49293258391275 \n",
      "Python PSNR: 21.492932823446132\n"
     ]
    }
   ],
   "source": [
    "lena_original = cv2.imread('Resources/ImageComparison/lena.png')\n",
    "lena_matlab = cv2.imread('Resources/ImageComparison/lena_matlab.png')\n",
    "lena_python = cv2.imread('Resources/ImageComparison/lena_python.png')\n",
    "\n",
    "width, height, nb_channels = lena_original.shape\n",
    "max_pixel_value = np.iinfo(np.uint8).max\n",
    "\n",
    "matlab_mse = np.sum(np.square(lena_original.astype(int) - lena_matlab.astype(int))) / (width * height * nb_channels)\n",
    "python_mse = np.sum(np.square(lena_original.astype(int) - lena_python.astype(int))) / (width * height * nb_channels)\n",
    "matlab_psnr = 10 * np.log10((max_pixel_value ** 2) / matlab_mse)\n",
    "python_psnr = 10 * np.log10((max_pixel_value ** 2) / python_mse)\n",
    "\n",
    "print('MATLAB MSE:', matlab_mse, '\\nPython MSE:', python_mse)\n",
    "print('MATLAB PSNR:', matlab_psnr, '\\nPython PSNR:', python_psnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY CODE TESTS BELOW THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
