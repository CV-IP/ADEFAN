{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import concurrent.futures as multithreading\n",
    "from scipy.stats import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Video:\n",
    "    \n",
    "    @staticmethod\n",
    "    def compress(filename, output_dst=None, fraction=0.01):\n",
    "\n",
    "        def get_indices(height, width, fraction):\n",
    "\n",
    "            def to_2d(index):\n",
    "                return (index // width, index % width)\n",
    "\n",
    "            samples = np.random.permutation(width * height)[:int(width * height * fraction)]\n",
    "\n",
    "            indices = [to_2d(index) for index in samples]\n",
    "\n",
    "            return tuple(zip(*indices))\n",
    "\n",
    "\n",
    "        def sample_frame(frame, fraction):\n",
    "            height, width, nb_channels = frame.shape\n",
    "\n",
    "            indices = get_indices(height, width, fraction)\n",
    "\n",
    "            return np.expand_dims(frame[indices], axis=0)\n",
    "\n",
    "\n",
    "        seed = np.array(np.random.randint(0, np.iinfo(np.int32).max))\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        cap = cv2.VideoCapture(filename)\n",
    "        framerate = np.array(cap.get(cv2.cv2.CAP_PROP_FPS))\n",
    "\n",
    "        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        start_time = time.time()\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "        dimensions = np.array(frame.shape)\n",
    "\n",
    "        video = sample_frame(frame, fraction)\n",
    "        curr_frame = 1\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            sampled_frame = sample_frame(frame, fraction)\n",
    "\n",
    "            video = np.vstack((video, sampled_frame))\n",
    "\n",
    "            curr_frame += 1\n",
    "            print('Compressing Video: ' + str(int(100 * curr_frame / num_frames)) + \n",
    "                  '%\\tTime Elapsed: ' + str(int(np.floor(time.time() - start_time))) + ' seconds', end='\\r')\n",
    "\n",
    "        cap.release()\n",
    "\n",
    "        print('Compressing Video: 100%\\tTime Elapsed: ' + str(int(np.floor(time.time() - start_time))) + ' seconds')\n",
    "\n",
    "        if output_dst is None:\n",
    "            output_dst = '../Results/CompressedVideos/' + filename.split('/')[-1].split('.')[0]\n",
    "        \n",
    "        np.savez_compressed(\n",
    "            output_dst, \n",
    "            video=video, \n",
    "            dimensions=dimensions, \n",
    "            framerate=framerate,\n",
    "            seed=seed,\n",
    "            fraction=np.array(fraction)\n",
    "        )\n",
    "    \n",
    "    @staticmethod\n",
    "    def psnr(original, reconstructed, color_channels='bgr'):\n",
    "        cap_original = cv2.VideoCapture(original)\n",
    "        cap_reconstructed = cv2.VideoCapture(reconstructed)\n",
    "        \n",
    "        num_frames_original = int(cap_original.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        num_frames_reconstructed = int(cap_reconstructed.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        num_frames = min(num_frames_original, num_frames_reconstructed)\n",
    "        \n",
    "        mse_list = []\n",
    "        max_pixel_value = np.iinfo(np.uint8).max\n",
    "        \n",
    "        start_time = time.time()\n",
    "        curr_frame = 0\n",
    "        \n",
    "        while cap_original.isOpened() and cap_reconstructed.isOpened():\n",
    "            ret_original, frame_original = cap_original.read()\n",
    "            ret_reconstructed, frame_reconstructed = cap_reconstructed.read()\n",
    "            \n",
    "            if (not ret_original) or (not ret_reconstructed):\n",
    "                break\n",
    "            \n",
    "            height = frame_original.shape[0]\n",
    "            width = frame_original.shape[1]\n",
    "            frame_mse = 0\n",
    "            \n",
    "            if color_channels == 'bgr':\n",
    "                nb_channels = frame_original.shape[2]\n",
    "                total_squared_error = np.sum(np.square(frame_original.astype(int) - \n",
    "                                                       frame_reconstructed.astype(int)))\n",
    "                frame_mse = total_squared_error / (width * height * nb_channels)\n",
    "            \n",
    "            elif color_channels == 'ycrcb':\n",
    "                frame_original = cv2.cvtColor(frame_original, cv2.COLOR_BGR2YCrCb)\n",
    "                frame_reconstructed = cv2.cvtColor(frame_reconstructed, cv2.COLOR_BGR2YCrCb)\n",
    "                total_squared_error = np.sum(np.square(frame_original[:,:,0].astype(int) - \n",
    "                                                       frame_reconstructed[:,:,0].astype(int)))\n",
    "                frame_mse = total_squared_error / (width * height)\n",
    "            \n",
    "            mse_list.append(frame_mse)\n",
    "            \n",
    "            curr_frame += 1\n",
    "            print('Computing PSNR: ' + str(int(100 * curr_frame / num_frames)) +\n",
    "                  '%\\tTime Elapsed: ' + str(int(np.floor(time.time() - start_time))) + ' seconds', end='\\r')\n",
    "        \n",
    "        mse = np.mean(mse_list)\n",
    "        psnr = 10 * np.log10((max_pixel_value ** 2) / mse)\n",
    "        \n",
    "        print('Computing PSNR: 100%\\tTime Elapsed: ' + str(int(np.floor(time.time() - start_time))) + ' seconds')\n",
    "        \n",
    "        cap_original.release()\n",
    "        cap_reconstructed.release()\n",
    "        \n",
    "        return psnr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kernels:\n",
    "    \n",
    "    @staticmethod\n",
    "    def kernel_2d(kernel_size, sigma):\n",
    "        center = kernel_size // 2\n",
    "        kernel = np.fromfunction(\n",
    "            lambda x, y: \n",
    "                np.exp( -0.5 * ((x - center) ** 2 + (y - center) ** 2) / (sigma ** 2)), \n",
    "            (kernel_size, kernel_size), \n",
    "            dtype=float)\n",
    "\n",
    "        return kernel\n",
    "    \n",
    "    @staticmethod\n",
    "    def kernel_3d(kernel_size, sigma, num_kernels, sigma_time):\n",
    "        center = kernel_size // 2\n",
    "        kernels = np.fromfunction(\n",
    "            lambda t, x, y: \n",
    "                np.exp( -0.5 * (\n",
    "                                 (((x - center) ** 2 + (y - center) ** 2) / (sigma ** 2)) + \n",
    "                                  ((t ** 2) / (sigma_time ** 2))\n",
    "                               )\n",
    "                      ), \n",
    "            (num_kernels, kernel_size, kernel_size), \n",
    "            dtype=float\n",
    "        )\n",
    "        return kernels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompressedVideo:\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        \n",
    "        file_dict = np.load(filename)\n",
    "        \n",
    "        self.filename = filename.split('.npz')[0]\n",
    "        self.height = file_dict['dimensions'][0]\n",
    "        self.width = file_dict['dimensions'][1]\n",
    "        self.nb_channels = file_dict['dimensions'][2]\n",
    "        self.video = file_dict['video']\n",
    "        self.num_frames = self.video.shape[0]\n",
    "        self.framerate = file_dict['framerate']\n",
    "        self.seed = file_dict['seed']\n",
    "        self.fraction = file_dict['fraction']\n",
    "        \n",
    "        # Create indices from seed\n",
    "        def indices_generator():\n",
    "            np.random.seed(self.seed)\n",
    "            for idx in range(self.num_frames):\n",
    "                samples = np.random.permutation(self.width * self.height)[:int(self.width * self.height * self.fraction)]\n",
    "                yield tuple(zip(*[(index // self.width, index % self.width) for index in samples]))\n",
    "        \n",
    "        self.indices = np.array([i for i in indices_generator()])\n",
    "        \n",
    "        \n",
    "        self.defaults = {}\n",
    "        self.defaults['sigma']           = np.sqrt((self.height * self.width) / \n",
    "                                                   (self.video[0].shape[0] * np.pi))\n",
    "        self.defaults['kernel_size']     = 2 * (int(0.5 + 3 * self.defaults['sigma']) + 2) + 1\n",
    "        self.defaults['num_time_frames'] = 15\n",
    "        self.defaults['output_dst']      = self.filename + '_reconstructed.mov'\n",
    "        self.defaults['multithreaded']   = True\n",
    "        self.defaults['alpha']           = 0.95\n",
    "        self.defaults['beta']            = 80\n",
    "        self.defaults['window_width']    = 150\n",
    "        self.defaults['window_overlap']  = 0.5\n",
    "    \n",
    "    \n",
    "    def reconstruct(self, algorithm='efan2d', color_channels='bgr', verbose=False, **kwargs):\n",
    "        \n",
    "        if 'kernel_size' in kwargs:\n",
    "            kernel_size = kwargs['kernel_size']\n",
    "        else:\n",
    "            kernel_size = self.defaults['kernel_size']\n",
    "        \n",
    "        if 'sigma' in kwargs:\n",
    "            sigma = kwargs['sigma']\n",
    "        else:\n",
    "            sigma = self.defaults['sigma']\n",
    "        \n",
    "        if 'num_time_frames' in kwargs:\n",
    "            num_time_frames = kwargs['num_time_frames']\n",
    "        else:\n",
    "            num_time_frames = self.defaults['num_time_frames']\n",
    "        \n",
    "        if 'output_dst' in kwargs:\n",
    "            output_dst = kwargs['output_dst']\n",
    "        else:\n",
    "            output_dst = self.defaults['output_dst']\n",
    "        \n",
    "        if 'multithreaded' in kwargs:\n",
    "            multithreaded = kwargs['multithreaded']\n",
    "        else:\n",
    "            multithreaded = self.defaults['multithreaded']\n",
    "        \n",
    "        if 'alpha' in kwargs:\n",
    "            alpha = kwargs['alpha']\n",
    "        else:\n",
    "            alpha = self.defaults['alpha']\n",
    "        \n",
    "        if 'beta' in kwargs:\n",
    "            beta = kwargs['beta']\n",
    "        else:\n",
    "            beta = self.defaults['beta']\n",
    "        \n",
    "        if 'window_width' in kwargs:\n",
    "            window_width = kwargs['window_width']\n",
    "        else:\n",
    "            window_width = self.defaults['window_width']\n",
    "        \n",
    "        if 'window_overlap' in kwargs:\n",
    "            window_overlap = kwargs['window_overlap']\n",
    "        else:\n",
    "            window_overlap = self.defaults['window_overlap']\n",
    "        \n",
    "        \n",
    "        def display_progress(frame_index, start_time, filter_times, complete=False):\n",
    "            if verbose:\n",
    "                print('Reconstructing Video: ' + str(int(100 * frame_index / self.num_frames)) + '% ' + \n",
    "                      '\\tTime Elapsed: ' + str(int(np.floor(time.time() - start_time))) + ' seconds ' +\n",
    "                      '\\tFilter Time: '  + str(int(np.floor(np.sum(filter_times)))) + ' seconds', end='\\r')\n",
    "\n",
    "                if complete:\n",
    "                    print('')\n",
    "        \n",
    "        \n",
    "        def prepare_frame(frame_index):\n",
    "            frame = self.video[frame_index]\n",
    "            indices = self.indices[frame_index]\n",
    "\n",
    "            black_frame = np.zeros((self.height, self.width, self.nb_channels))\n",
    "                \n",
    "            if color_channels == 'ycrcb':\n",
    "                frame = cv2.cvtColor(np.expand_dims(frame, axis=0), cv2.COLOR_BGR2YCrCb)[0]\n",
    "            \n",
    "            black_frame[tuple(indices)] = frame\n",
    "\n",
    "            new_channel = np.zeros((self.height, self.width, 1)) + 1e-10 # To avoid division by zero\n",
    "            new_channel[tuple(indices)] = 1.0\n",
    "\n",
    "            augmented_frame = np.append(black_frame, new_channel, axis=2)\n",
    "            \n",
    "            return augmented_frame\n",
    "        \n",
    "        \n",
    "        def normalize_frame(frame):\n",
    "            for i in range(self.nb_channels):\n",
    "                frame[:,:,i] /= frame[:,:,-1]\n",
    "\n",
    "            reconstructed_frame = (frame[:,:,:-1] + 0.5).astype(np.uint8)\n",
    "            \n",
    "            return reconstructed_frame\n",
    "        \n",
    "        \n",
    "        def efan2d(output):\n",
    "            \"\"\"\n",
    "            EFAN2D Algorithm\n",
    "            \"\"\"\n",
    "            \n",
    "            filter_times = []\n",
    "\n",
    "            def filter_frame(frame_index, kernel):\n",
    "                augmented_frame = prepare_frame(frame_index)\n",
    "\n",
    "                st = time.time()\n",
    "                filtered = cv2.filter2D(augmented_frame, -1, kernel, \n",
    "                                        borderType=cv2.BORDER_CONSTANT)\n",
    "                filter_times.append(time.time() - st)\n",
    "                \n",
    "                return filtered\n",
    "            \n",
    "            \n",
    "            def reconstruct_frame(frame_index, kernel):\n",
    "                filtered = filter_frame(frame_index, kernel)\n",
    "                \n",
    "                reconstructed_frame = normalize_frame(filtered)\n",
    "                # Not sure about this, paper formula for reconstruction does not include it\n",
    "                #reconstructed_frame[tuple(indices)] = frame\n",
    "                \n",
    "                return reconstructed_frame\n",
    "            \n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            kernel = Kernels.kernel_2d(kernel_size, sigma)\n",
    "            \n",
    "            display_progress(0, start_time, filter_times)\n",
    "            \n",
    "            for frame_index in range(self.num_frames):\n",
    "                reconstructed_frame = reconstruct_frame(frame_index, kernel)\n",
    "                \n",
    "                if color_channels == 'ycrcb':\n",
    "                    reconstructed_frame = cv2.cvtColor(reconstructed_frame, cv2.COLOR_YCrCb2BGR)\n",
    "                \n",
    "                output.write(reconstructed_frame)\n",
    "                display_progress(frame_index, start_time, filter_times)\n",
    "            \n",
    "            display_progress(self.num_frames, start_time, filter_times, complete=True)\n",
    "\n",
    "\n",
    "        def efan3d(output):\n",
    "            \"\"\"\n",
    "            EFAN3D Algorithm\n",
    "            \"\"\"\n",
    "            \n",
    "            num_kernels = (num_time_frames + 1) // 2\n",
    "            sigma_time = (num_kernels - 1) / 6\n",
    "            \n",
    "            filter_times = []\n",
    "            \n",
    "            def filter_frame(frame_index, kernels):\n",
    "                augmented_frame = prepare_frame(frame_index)\n",
    "\n",
    "                st = time.time()\n",
    "                \n",
    "                if multithreaded:\n",
    "                    filtered_frame = [None for i in range(num_kernels)]\n",
    "\n",
    "                    def apply_kernel(kernel_index):\n",
    "                        filtered = cv2.filter2D(augmented_frame, -1, kernels[kernel_index], \n",
    "                                                borderType=cv2.BORDER_CONSTANT)\n",
    "                        filtered_frame[kernel_index] = filtered\n",
    "\n",
    "                    with multithreading.ThreadPoolExecutor(max_workers=num_kernels) as executor:\n",
    "                        executor.map(apply_kernel, range(num_kernels))\n",
    "                \n",
    "                else:\n",
    "                    filtered_frame = []\n",
    "                    for kernel in kernels:\n",
    "                        filtered = cv2.filter2D(augmented_frame, -1, kernel, \n",
    "                                                borderType=cv2.BORDER_CONSTANT)\n",
    "                        filtered_frame.append(filtered)\n",
    "                \n",
    "                filter_times.append(time.time() - st)\n",
    "                \n",
    "                return filtered_frame\n",
    "            \n",
    "            \n",
    "            def reconstruct_frame(frame_index, filtered_frames):\n",
    "                filtered_sum = np.zeros((self.height, self.width, self.nb_channels + 1))\n",
    "            \n",
    "                nb_past_frames = min(frame_index, num_kernels - 1)\n",
    "                for idx in range(nb_past_frames):\n",
    "                    filtered_sum += filtered_frames[idx][nb_past_frames - idx]\n",
    "\n",
    "                nb_future_frames = min(self.num_frames - frame_index, num_kernels)\n",
    "                for idx in range(nb_future_frames):\n",
    "                    filtered_sum += filtered_frames[min(frame_index, num_kernels - 1) + idx][idx]\n",
    "                \n",
    "                reconstructed_frame = normalize_frame(filtered_sum)\n",
    "                \n",
    "                return reconstructed_frame\n",
    "            \n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            kernels = Kernels.kernel_3d(kernel_size, sigma, num_kernels, sigma_time)\n",
    "            \n",
    "            filtered_frames = []\n",
    "            \n",
    "            display_progress(0, start_time, filter_times)\n",
    "            \n",
    "            for frame_index in range(self.num_frames):\n",
    "                \n",
    "                if frame_index == 0:\n",
    "                    for idx in range(num_kernels):\n",
    "                        filtered_frames.append(filter_frame(idx, kernels))\n",
    "                        \n",
    "                elif frame_index < num_kernels:\n",
    "                    filtered_frames.append(filter_frame((num_kernels - 1) + frame_index, kernels))\n",
    "                    \n",
    "                elif frame_index <= self.num_frames - num_kernels:\n",
    "                    filtered_frames.append(filter_frame((num_kernels - 1) + frame_index, kernels))\n",
    "                    filtered_frames = filtered_frames[1:]\n",
    "                    \n",
    "                else:\n",
    "                    filtered_frames = filtered_frames[1:]\n",
    "                \n",
    "                reconstructed_frame = reconstruct_frame(frame_index, filtered_frames)\n",
    "                \n",
    "                if color_channels == 'ycrcb':\n",
    "                    reconstructed_frame = cv2.cvtColor(reconstructed_frame, cv2.COLOR_YCrCb2BGR)\n",
    "                \n",
    "                output.write(reconstructed_frame)\n",
    "                \n",
    "                display_progress(frame_index, start_time, filter_times)\n",
    "            \n",
    "            display_progress(self.num_frames, start_time, filter_times, complete=True)\n",
    "        \n",
    "        \n",
    "        def adefan(output):\n",
    "            \n",
    "            num_kernels = (num_time_frames + 1) // 2\n",
    "            sigma_time = (num_kernels - 1) / 6\n",
    "            uniform = np.ones(np.iinfo(np.uint8).max + 1) / (np.iinfo(np.uint8).max + 1)\n",
    "            \n",
    "            filter_times = []\n",
    "            \n",
    "            def intervals(length):\n",
    "                return [slice(x, min(x + window_width, length)) for x in \n",
    "                        range(0, length - int(window_width * window_overlap), \n",
    "                              int(window_width * (1 - window_overlap)))]\n",
    "        \n",
    "        \n",
    "            def window_color_distributions(window):\n",
    "\n",
    "                return np.array([alpha * np.histogram(window[:,channel], \n",
    "                                                      bins=range(np.iinfo(np.uint8).max + 2), \n",
    "                                                      density=True)[0] +\n",
    "                                 (1 - alpha) * uniform\n",
    "                                 for channel in range(self.nb_channels)]).flatten()\n",
    "            \n",
    "            \n",
    "            def preprocess_frame(frame_index, windows):\n",
    "                augmented_frame = prepare_frame(frame_index)\n",
    "                \n",
    "                frame_color_distributions = [\n",
    "                    window_color_distributions(\n",
    "                        augmented_frame[window][augmented_frame[window][:,:,-1] == 1][:,:-1]\n",
    "                    ) for window in windows\n",
    "                ]\n",
    "                \n",
    "                return augmented_frame, frame_color_distributions\n",
    "            \n",
    "            \n",
    "            def compute_max_divergence(frame_index, frames_color_distributions):\n",
    "                \n",
    "                curr_frame_distributions = frames_color_distributions[min(frame_index, num_kernels - 1)]\n",
    "                \n",
    "            \n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            windows = [(x, y) for x in intervals(self.width) for y in intervals(self.height)]\n",
    "            augmented_frames = []\n",
    "            frames_color_distributions = []\n",
    "            \n",
    "            for frame_index in  range(self.num_frames):\n",
    "                \n",
    "                st = time.time()\n",
    "                \n",
    "                if frame_index == 0:\n",
    "                    for idx in range(num_kernels):\n",
    "                        augmented_frame, frame_color_distributions = preprocess_frame(idx, windows)\n",
    "                        \n",
    "                        augmented_frames.append(augmented_frame)\n",
    "                        frames_color_distributions.append(frame_color_distributions)\n",
    "                \n",
    "                elif frame_index < num_kernels:\n",
    "                    augmented_frame, frame_color_distributions = preprocess_frame(idx, windows)\n",
    "                    \n",
    "                    augmented_frames.append(augmented_frame)\n",
    "                    frames_color_distributions.append(frame_color_distributions)\n",
    "                    \n",
    "                elif frame_index <= self.num_frames - num_kernels:\n",
    "                    augmented_frame, frame_color_distributions = preprocess_frame(idx, windows)\n",
    "                    \n",
    "                    augmented_frames.append(augmented_frame)\n",
    "                    frames_color_distributions.append(frame_color_distributions)\n",
    "                    \n",
    "                    augmented_frames           = augmented_frames[1:]\n",
    "                    frames_color_distributions = frames_color_distributions[1:]\n",
    "                    \n",
    "                else:\n",
    "                    augmented_frames           = augmented_frames[1:]\n",
    "                    frames_color_distributions = frames_color_distributions[1:]\n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                \n",
    "                filter_times.append(time.time() - st)\n",
    "                display_progress(frame_index, start_time, filter_times)\n",
    "            display_progress(self.num_frames, start_time, filter_times, complete=True)\n",
    "                \n",
    "            \n",
    "            \n",
    "            \n",
    "            #############################################\n",
    "        \n",
    "        \n",
    "        output = cv2.VideoWriter(\n",
    "                    output_dst, \n",
    "                    cv2.VideoWriter_fourcc('M','J','P','G'), \n",
    "                    self.framerate, \n",
    "                    (self.width, self.height)\n",
    "                 )\n",
    "        \n",
    "        if algorithm == 'efan2d':\n",
    "            efan2d(output)\n",
    "        elif algorithm == 'efan3d':\n",
    "            efan3d(output)\n",
    "        elif algorithm == 'adefan':\n",
    "            adefan(output)\n",
    "        \n",
    "        output.release()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_frame(idx):\n",
    "    frame = seal.video[idx]\n",
    "    indices = seal.indices[idx]\n",
    "\n",
    "    black_frame = np.zeros((seal.height, seal.width, seal.nb_channels))\n",
    "    black_frame[tuple(indices)] = frame\n",
    "\n",
    "    new_channel = np.zeros((seal.height, seal.width, 1)) + 1e-10 # To avoid division by zero\n",
    "    new_channel[tuple(indices)] = 1.0\n",
    "\n",
    "    augmented_frame = np.append(black_frame, new_channel, axis=2)\n",
    "\n",
    "    return augmented_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "af = prepare_frame(0)\n",
    "af2 = prepare_frame(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[250., 254., 255.],\n",
       "       [244., 248., 255.],\n",
       "       [246., 250., 255.],\n",
       "       [249., 253., 255.],\n",
       "       [249., 253., 255.],\n",
       "       [248., 252., 255.],\n",
       "       [249., 253., 255.],\n",
       "       [248., 252., 255.],\n",
       "       [239., 243., 252.],\n",
       "       [243., 247., 255.],\n",
       "       [241., 245., 254.],\n",
       "       [244., 248., 255.],\n",
       "       [249., 253., 255.],\n",
       "       [243., 247., 255.],\n",
       "       [242., 246., 255.],\n",
       "       [239., 243., 252.],\n",
       "       [243., 247., 255.],\n",
       "       [238., 242., 251.],\n",
       "       [245., 249., 255.],\n",
       "       [239., 243., 252.],\n",
       "       [250., 254., 255.],\n",
       "       [248., 252., 255.],\n",
       "       [246., 250., 255.],\n",
       "       [237., 241., 250.],\n",
       "       [241., 245., 254.],\n",
       "       [244., 248., 255.],\n",
       "       [232., 236., 245.],\n",
       "       [248., 252., 255.],\n",
       "       [243., 248., 255.],\n",
       "       [243., 248., 255.],\n",
       "       [248., 252., 255.],\n",
       "       [241., 248., 255.],\n",
       "       [241., 248., 255.],\n",
       "       [238., 242., 251.],\n",
       "       [242., 246., 255.],\n",
       "       [242., 247., 255.],\n",
       "       [244., 248., 255.],\n",
       "       [242., 246., 255.],\n",
       "       [229., 239., 251.],\n",
       "       [242., 248., 255.],\n",
       "       [212., 223., 238.],\n",
       "       [210., 219., 234.],\n",
       "       [199., 210., 225.],\n",
       "       [193., 204., 219.],\n",
       "       [186., 199., 215.],\n",
       "       [179., 195., 214.],\n",
       "       [180., 194., 213.],\n",
       "       [180., 194., 213.],\n",
       "       [178., 194., 213.],\n",
       "       [178., 194., 213.],\n",
       "       [178., 193., 214.],\n",
       "       [175., 190., 211.],\n",
       "       [176., 191., 212.],\n",
       "       [178., 193., 214.],\n",
       "       [178., 193., 214.],\n",
       "       [178., 193., 214.],\n",
       "       [176., 191., 212.],\n",
       "       [176., 191., 212.],\n",
       "       [175., 190., 211.],\n",
       "       [174., 189., 210.],\n",
       "       [176., 191., 212.],\n",
       "       [174., 189., 210.],\n",
       "       [178., 193., 214.],\n",
       "       [173., 188., 209.],\n",
       "       [178., 193., 214.],\n",
       "       [173., 188., 209.],\n",
       "       [171., 186., 207.],\n",
       "       [176., 191., 212.],\n",
       "       [176., 191., 212.],\n",
       "       [176., 191., 212.],\n",
       "       [173., 188., 209.],\n",
       "       [173., 188., 209.],\n",
       "       [174., 189., 210.],\n",
       "       [153., 168., 189.],\n",
       "       [171., 186., 207.],\n",
       "       [174., 189., 210.],\n",
       "       [174., 189., 210.],\n",
       "       [170., 188., 208.],\n",
       "       [166., 184., 204.],\n",
       "       [151., 169., 189.],\n",
       "       [160., 178., 198.],\n",
       "       [145., 163., 183.],\n",
       "       [169., 187., 207.],\n",
       "       [129., 147., 167.],\n",
       "       [152., 170., 190.],\n",
       "       [166., 184., 204.],\n",
       "       [169., 184., 205.],\n",
       "       [169., 187., 207.],\n",
       "       [160., 178., 198.],\n",
       "       [169., 187., 207.],\n",
       "       [117., 135., 155.],\n",
       "       [168., 183., 204.],\n",
       "       [167., 185., 205.],\n",
       "       [120., 138., 158.],\n",
       "       [116., 134., 154.],\n",
       "       [134., 154., 174.],\n",
       "       [134., 152., 172.],\n",
       "       [143., 161., 181.],\n",
       "       [133., 151., 171.],\n",
       "       [117., 135., 155.],\n",
       "       [155., 173., 193.],\n",
       "       [165., 183., 203.],\n",
       "       [167., 182., 203.],\n",
       "       [168., 184., 203.],\n",
       "       [164., 182., 202.],\n",
       "       [167., 182., 205.],\n",
       "       [166., 181., 202.],\n",
       "       [162., 180., 200.],\n",
       "       [165., 180., 201.],\n",
       "       [168., 183., 204.],\n",
       "       [166., 181., 202.],\n",
       "       [166., 181., 202.],\n",
       "       [162., 178., 197.],\n",
       "       [164., 179., 200.],\n",
       "       [161., 177., 196.],\n",
       "       [162., 178., 197.],\n",
       "       [162., 180., 200.],\n",
       "       [160., 176., 195.],\n",
       "       [158., 177., 195.],\n",
       "       [161., 176., 197.],\n",
       "       [158., 174., 193.],\n",
       "       [158., 177., 195.],\n",
       "       [158., 177., 195.],\n",
       "       [159., 178., 196.],\n",
       "       [161., 176., 197.],\n",
       "       [158., 174., 193.],\n",
       "       [160., 176., 195.],\n",
       "       [160., 176., 195.],\n",
       "       [156., 174., 194.],\n",
       "       [157., 176., 194.],\n",
       "       [155., 174., 192.],\n",
       "       [156., 175., 193.],\n",
       "       [155., 174., 192.],\n",
       "       [156., 175., 193.],\n",
       "       [158., 177., 195.],\n",
       "       [155., 174., 192.],\n",
       "       [157., 176., 194.],\n",
       "       [155., 174., 192.],\n",
       "       [153., 172., 190.],\n",
       "       [156., 175., 193.],\n",
       "       [157., 176., 194.],\n",
       "       [153., 172., 190.],\n",
       "       [153., 172., 190.],\n",
       "       [155., 174., 192.],\n",
       "       [151., 170., 188.],\n",
       "       [152., 171., 189.],\n",
       "       [153., 172., 190.],\n",
       "       [155., 174., 192.],\n",
       "       [155., 174., 192.],\n",
       "       [152., 171., 189.],\n",
       "       [153., 172., 190.],\n",
       "       [152., 171., 189.],\n",
       "       [152., 171., 189.],\n",
       "       [153., 172., 190.],\n",
       "       [149., 168., 186.],\n",
       "       [153., 172., 190.],\n",
       "       [153., 172., 190.],\n",
       "       [152., 171., 189.],\n",
       "       [151., 170., 188.],\n",
       "       [151., 170., 188.],\n",
       "       [152., 171., 189.],\n",
       "       [151., 170., 188.],\n",
       "       [152., 171., 189.],\n",
       "       [150., 169., 187.],\n",
       "       [153., 172., 190.],\n",
       "       [148., 167., 185.],\n",
       "       [152., 171., 189.],\n",
       "       [152., 171., 189.],\n",
       "       [150., 169., 187.],\n",
       "       [152., 171., 189.],\n",
       "       [150., 169., 187.],\n",
       "       [151., 170., 188.],\n",
       "       [153., 172., 190.],\n",
       "       [150., 169., 187.],\n",
       "       [150., 169., 187.],\n",
       "       [151., 170., 188.],\n",
       "       [151., 170., 188.],\n",
       "       [150., 169., 187.],\n",
       "       [152., 171., 189.],\n",
       "       [150., 169., 187.],\n",
       "       [151., 170., 188.],\n",
       "       [153., 172., 190.],\n",
       "       [150., 169., 187.],\n",
       "       [151., 170., 188.],\n",
       "       [151., 170., 188.],\n",
       "       [149., 168., 186.],\n",
       "       [150., 169., 187.],\n",
       "       [148., 167., 185.],\n",
       "       [148., 167., 185.],\n",
       "       [149., 168., 186.],\n",
       "       [149., 168., 186.],\n",
       "       [149., 168., 186.],\n",
       "       [148., 167., 185.],\n",
       "       [152., 171., 189.],\n",
       "       [148., 167., 185.],\n",
       "       [148., 167., 185.],\n",
       "       [151., 170., 188.],\n",
       "       [146., 162., 181.],\n",
       "       [147., 166., 184.],\n",
       "       [148., 167., 185.],\n",
       "       [148., 167., 185.],\n",
       "       [145., 164., 182.],\n",
       "       [152., 171., 189.],\n",
       "       [149., 168., 186.],\n",
       "       [147., 166., 184.],\n",
       "       [148., 167., 185.],\n",
       "       [150., 169., 187.],\n",
       "       [144., 163., 181.],\n",
       "       [144., 163., 181.],\n",
       "       [149., 168., 186.],\n",
       "       [147., 166., 184.],\n",
       "       [150., 169., 187.],\n",
       "       [147., 166., 184.],\n",
       "       [147., 166., 184.],\n",
       "       [147., 166., 184.],\n",
       "       [144., 160., 179.],\n",
       "       [145., 164., 182.],\n",
       "       [145., 164., 182.],\n",
       "       [144., 163., 181.],\n",
       "       [147., 166., 184.],\n",
       "       [152., 171., 189.],\n",
       "       [144., 163., 181.],\n",
       "       [145., 164., 182.],\n",
       "       [150., 169., 187.],\n",
       "       [143., 162., 180.],\n",
       "       [141., 161., 181.],\n",
       "       [145., 164., 182.],\n",
       "       [143., 162., 180.],\n",
       "       [142., 162., 182.],\n",
       "       [143., 161., 181.]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(af[:150,:150])[(af[:150,:150])[:,:,-1] == 1][:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_width = 150\n",
    "window_overlap = 0.5\n",
    "\n",
    "def intervals(length):\n",
    "    return [slice(x, min(x + window_width, length)) for x in \n",
    "            range(0, length - int(window_width * window_overlap), \n",
    "                  int(window_width * (1 - window_overlap)))]\n",
    "\n",
    "windows = [(x, y) for x in intervals(seal.width) for y in intervals(seal.height)]\n",
    "len(windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004102945327758789\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "for window in windows:\n",
    "    af[window][af[window][:,:,3] == 1][:,:-1]\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.95\n",
    "uniform = np.ones(np.iinfo(np.uint8).max + 1) / (np.iinfo(np.uint8).max + 1)\n",
    "def window_color_distributions(window):\n",
    "\n",
    "    return np.array([alpha * np.histogram(window[:,channel], \n",
    "                                          bins=range(np.iinfo(np.uint8).max + 2), \n",
    "                                          density=True)[0] +\n",
    "                     (1 - alpha) * uniform\n",
    "                     for channel in range(seal.nb_channels)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = window_color_distributions(af[windows[1]][af[windows[1]][:,:,-1] == 1][:,:-1])\n",
    "d2 = window_color_distributions(af2[windows[1]][af2[windows[1]][:,:,-1] == 1][:,:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4709375744677732"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy(d1,d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Validation:\n",
    "    \n",
    "    resources_folder = '../Resources/Videos/'\n",
    "    compressed_folder = '../Results/CompressedVideos/'\n",
    "    reconstructed_folder = '../Results/ReconstructedVideos/'\n",
    "    \n",
    "    @staticmethod\n",
    "    def compress_videos(motion='both'):\n",
    "        \n",
    "        def compress_folder_content(folder):\n",
    "            suffix = folder + '/'\n",
    "            in_folder = Validation.resources_folder + suffix\n",
    "            out_folder = Validation.compressed_folder + suffix\n",
    "            \n",
    "            for video in os.listdir(in_folder):\n",
    "                video_name = video.split('.')[0]\n",
    "                Video.compress(in_folder + video, out_folder + video_name)\n",
    "        \n",
    "        if motion == 'absent' or motion == 'both':\n",
    "            compress_folder_content('MotionAbsent')\n",
    "        \n",
    "        if motion == 'present' or motion == 'both':\n",
    "            compress_folder_content('MotionPresent')\n",
    "    \n",
    "    @staticmethod\n",
    "    def reconstruct_videos(algorithm='efan2d', motion='both', extension='.mov', color_channels='bgr'):\n",
    "        \n",
    "        def reconstruct_folder_content(folder):\n",
    "            suffix = folder + '/'\n",
    "            algorithm_folder = algorithm.upper() + '/'\n",
    "            in_folder = Validation.compressed_folder + suffix\n",
    "            out_folder = Validation.reconstructed_folder + algorithm_folder + suffix\n",
    "            \n",
    "            for video in os.listdir(in_folder):\n",
    "                video_name = video.split('.')[0]\n",
    "                out_filename = video_name + extension\n",
    "                compressed_video = CompressedVideo(in_folder + video)\n",
    "                compressed_video.reconstruct(algorithm=algorithm, \n",
    "                                             output_dst=out_folder+out_filename, \n",
    "                                             color_channels=color_channels)\n",
    "        \n",
    "        if motion == 'absent' or motion == 'both':\n",
    "            reconstruct_folder_content('MotionAbsent')\n",
    "\n",
    "        if motion == 'present' or motion == 'both':\n",
    "            reconstruct_folder_content('MotionPresent')\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_mean_psnr(algorithm='efan2d', motion='absent', color_channels='bgr'):\n",
    "        \n",
    "        def compute_folder_mean_psnr(folder):\n",
    "            psnr_list = []\n",
    "            \n",
    "            suffix = folder + '/'\n",
    "            original_folder = Validation.resources_folder + suffix\n",
    "            algorithm_folder = algorithm.upper() + '/'\n",
    "            reconstructed_folder = Validation.reconstructed_folder + algorithm_folder + suffix\n",
    "            \n",
    "            for original, reconstructed in zip(os.listdir(original_folder), os.listdir(reconstructed_folder)):\n",
    "                psnr = Video.psnr(original_folder + original, \n",
    "                                  reconstructed_folder + reconstructed, \n",
    "                                  color_channels=color_channels)\n",
    "                psnr_list.append(psnr)\n",
    "            \n",
    "            return np.mean(psnr_list)\n",
    "        \n",
    "        if motion == 'absent':\n",
    "            return compute_folder_mean_psnr('MotionAbsent')\n",
    "        \n",
    "        if motion == 'present':\n",
    "            return compute_folder_mean_psnr('MotionPresent')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n"
     ]
    }
   ],
   "source": [
    "Video.compress('Resources/VideoSamples/Seal.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "seal = CompressedVideo('../Results/CompressedVideos/Seal.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 8 seconds \tFilter Time: 4 seconds\n"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='efan2d', color_channels='ycrcb', output_dst='../Results/seal_ef2.mov', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 22 seconds \tFilter Time: 13 seconds\r"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='efan3d', multithreaded=True, output_dst='../Results/seal_ef3.mov', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 50 seconds \tFilter Time: 41 seconds\r"
     ]
    }
   ],
   "source": [
    "seal.reconstruct(algorithm='efan3d', multithreaded=False, output_dst='../Results/seal_ef3singlethreaded.mov', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using smaller resolutions seems much more reasonnable given the computational costs of hd videos.\n",
    "Using multithreading for EFAN3D leads to a speedup of a factor 2 in runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seal.reconstruct(algorithm='adefan', output_dst='../Results/seal_adefan.mov', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21.823762138725613"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video.psnr('Resources/VideoSamples/Seal.mp4', '../Results/seal_ef2.mov', color_channels='ycrcb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compressing Video: 100%\tTime Elapsed: 4 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 0 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 4 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 0 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 0 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 5 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 3 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 2 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n",
      "Compressing Video: 100%\tTime Elapsed: 1 seconds\n"
     ]
    }
   ],
   "source": [
    "Validation.compress_videos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructing Video: 100% \tTime Elapsed: 27 seconds \tFilter Time: 15 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 3 seconds \tFilter Time: 2 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 8 seconds \tFilter Time: 4 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 26 seconds \tFilter Time: 14 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 11 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 5 seconds \tFilter Time: 2 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 13 seconds \tFilter Time: 7 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 6 seconds \tFilter Time: 3 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 12 seconds \tFilter Time: 7 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 23 seconds \tFilter Time: 13 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 20 seconds \tFilter Time: 11 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 13 seconds \tFilter Time: 7 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 18 seconds \tFilter Time: 10 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 13 seconds \tFilter Time: 7 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 12 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 11 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 15 seconds \tFilter Time: 8 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 17 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 10 seconds \tFilter Time: 5 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 12 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 6 seconds \tFilter Time: 3 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 18 seconds \tFilter Time: 10 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 17 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 11 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 13 seconds \tFilter Time: 7 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 15 seconds \tFilter Time: 8 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 32 seconds \tFilter Time: 18 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 7 seconds \tFilter Time: 4 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 23 seconds \tFilter Time: 13 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 11 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 19 seconds \tFilter Time: 11 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 16 seconds \tFilter Time: 9 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 12 seconds \tFilter Time: 6 seconds\n",
      "Reconstructing Video: 100% \tTime Elapsed: 11 seconds \tFilter Time: 6 seconds\n"
     ]
    }
   ],
   "source": [
    "Validation.reconstruct_videos(algorithm='efan2d', color_channels='ycrcb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 3 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 3 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.222866647707434"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation.compute_mean_psnr(motion='absent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 3 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 2 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.575506557571156"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation.compute_mean_psnr(motion='present')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.43480608669383"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation.compute_mean_psnr(motion='absent', color_channels='ycrcb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 1 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n",
      "Computing PSNR: 100%\tTime Elapsed: 0 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25.00315016637109"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validation.compute_mean_psnr(motion='present', color_channels='ycrcb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive python operations / array indexing: 29.6 hours\n",
      "Numpy (C) operations / array indexing: 9.6 minutes\n",
      "Numpy speedup: 185.0 times faster\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "##### Optimization Benchmark #####\n",
    "##################################\n",
    "\n",
    "height = 720\n",
    "width = 1280\n",
    "num_channels = 3\n",
    "length = 38 #seconds\n",
    "framerate = 24\n",
    "num_frames = length * framerate\n",
    "anchor_x = 400\n",
    "anchor_y = 400\n",
    "num_rand_pixels = (height * width) // 100\n",
    "\n",
    "kernel_size = 71\n",
    "kernel = Kernels.kernel_2d(kernel_size, 20)\n",
    "r = (kernel_size - 1) // 2\n",
    "\n",
    "###########################\n",
    "##### Naive Operation #####\n",
    "###########################\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "kernel_dict = {}\n",
    "for i in range(256):\n",
    "    kernel_dict[i] = kernel * i\n",
    "\n",
    "filtered = np.zeros((height, width, num_channels + 1));\n",
    "\n",
    "for idx in range(num_rand_pixels // 100):\n",
    "    k = kernel_dict[np.random.randint(0,256)]\n",
    "    for c in range(num_channels + 1):\n",
    "        for y in range(kernel_size):\n",
    "            for x in range(kernel_size):\n",
    "                filtered[anchor_x-r+y,anchor_y-r+x,c] += k[x,y]\n",
    "tot_time_naive = (time.time() - st) * num_frames * 100\n",
    "print('Naive python operations / array indexing:', np.around(tot_time_naive / 3600, 1), 'hours')\n",
    "\n",
    "###########################\n",
    "##### Numpy Optimized #####\n",
    "###########################\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "filtered = filtered = np.zeros((height, width, num_channels + 1));\n",
    "\n",
    "kernel_dict = {}\n",
    "for i in range(256):\n",
    "    kernel_dict[i] = kernel * i\n",
    "\n",
    "for i in range(num_rand_pixels):\n",
    "    for c in range(num_channels + 1):\n",
    "        filtered[anchor_y-r:anchor_y+r+1, anchor_x-r:anchor_x+r+1, c] += kernel_dict[np.random.randint(0,256)]\n",
    "\n",
    "tot_time_numpy = (time.time() - st) * num_frames\n",
    "print('Numpy (C) operations / array indexing:', np.around(tot_time_numpy / 60, 1), 'minutes')\n",
    "print('Numpy speedup:', np.around(tot_time_naive / tot_time_numpy, 1), 'times faster')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "The equivalent of the MATLAB / C++ implementation would take over 29 hours to reconstruct the video using python operations and almost 10 minutes using numpy operations. Since numpy is already written in C there isn't much more to do to speed up the additions / multiplications / array indexing. Even using numpy this is still more than 4 times slower than using opencv to interpolate the value of each pixel (Probably because of the time gained by using filter2D which uses the FFT algorithm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time elapsed 0.05006265640258789 seconds\n"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "##### MATLAB / Python comparison #####\n",
    "######################################\n",
    "\n",
    "import scipy.io as sio\n",
    "\n",
    "frame = cv2.imread('Resources/ImageComparison/lena.png')\n",
    "width = frame.shape[1]\n",
    "height = frame.shape[0]\n",
    "nb_channels = frame.shape[2]\n",
    "\n",
    "randvec = sio.loadmat('Resources/ImageComparison/randvec.mat')['randind'][0] - 1 # MATLAB indexing starts at 1\n",
    "\n",
    "st = time.time() # Start counting time\n",
    "\n",
    "indices = [(index % height, index // height) for index in randvec] # MATLAB is column major so we convert to row major\n",
    "indices = tuple(zip(*indices))\n",
    "\n",
    "black_frame = np.zeros((height, width, nb_channels))\n",
    "black_frame[indices] = frame[indices]\n",
    "\n",
    "new_channel = np.zeros((height, width, 1)) + 1e-10 # To avoid division by zero\n",
    "new_channel[indices] = 1.0\n",
    "\n",
    "augmented_frame = np.append(black_frame, new_channel, axis=2)\n",
    "\n",
    "sigma = np.sqrt((height * width) / (len(indices[0]) * np.pi))\n",
    "kernel_size = 2 * (int(0.5 + 3 * sigma) + 2) + 1\n",
    "\n",
    "kernel = Kernels.kernel_2d(kernel_size, sigma)\n",
    "\n",
    "filtered = cv2.filter2D(augmented_frame, -1, kernel, borderType=cv2.BORDER_CONSTANT)\n",
    "for i in range(nb_channels):\n",
    "    filtered[:,:,i] /= filtered[:,:,-1]\n",
    "reconstructed_frame = (filtered[:,:,:-1] + 0.5).astype(np.uint8)\n",
    "\n",
    "print('Total time elapsed', time.time() - st, 'seconds')\n",
    "\n",
    "cv2.imwrite('Resources/ImageComparison/lena_python.png', reconstructed_frame);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our method takes the same amount of time as the MATLAB / C++ implementation to reconstruct the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of different channel values: 2\n"
     ]
    }
   ],
   "source": [
    "lena_matlab = cv2.imread('Resources/ImageComparison/lena_matlab.png')\n",
    "lena_python = cv2.imread('Resources/ImageComparison/lena_python.png')\n",
    "\n",
    "print('Number of different channel values:', np.count_nonzero(lena_matlab - lena_python))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only 6 channel values differ between the two images so the methods are equivalent (those values are probably because of different rounding / precision between python and C++)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATLAB MSE: 61.019219716389976 \n",
      "Python MSE: 61.01919428507487\n",
      "MATLAB PSNR: 30.276137110691067 \n",
      "Python PSNR: 30.276138920724392\n"
     ]
    }
   ],
   "source": [
    "lena_original = cv2.imread('Resources/ImageComparison/lena.png')\n",
    "lena_matlab = cv2.imread('Resources/ImageComparison/lena_matlab.png')\n",
    "lena_python = cv2.imread('Resources/ImageComparison/lena_python.png')\n",
    "\n",
    "width, height, nb_channels = lena_original.shape\n",
    "max_pixel_value = np.iinfo(np.uint8).max\n",
    "\n",
    "matlab_mse = np.sum(np.square(lena_original - lena_matlab)) / (width * height * nb_channels)\n",
    "python_mse = np.sum(np.square(lena_original - lena_python)) / (width * height * nb_channels)\n",
    "matlab_psnr = 10 * np.log10((max_pixel_value ** 2) / matlab_mse)\n",
    "python_psnr = 10 * np.log10((max_pixel_value ** 2) / python_mse)\n",
    "\n",
    "print('MATLAB MSE:', matlab_mse, '\\nPython MSE:', python_mse)\n",
    "print('MATLAB PSNR:', matlab_psnr, '\\nPython PSNR:', python_psnr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONLY CODE TESTS BELOW THIS CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9000978469848633\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.95\n",
    "uniform = np.ones(256) / 256\n",
    "\n",
    "st = time.time()\n",
    "for i in range(seal.video.shape[0]):\n",
    "    a = np.histogram(seal.video[0][:,0], \n",
    "                     bins=range(np.iinfo(np.uint8).max + 2), density=True)[0]\n",
    "\n",
    "    b = np.histogram(seal.video[1][:,0], \n",
    "                     bins=range(np.iinfo(np.uint8).max + 2), density=True)[0]\n",
    "\n",
    "    a = alpha * a + (1 - alpha) * uniform\n",
    "    b = alpha * b + (1 - alpha) * uniform\n",
    "    \n",
    "    for i in range(200):\n",
    "        entropy(a, b)\n",
    "print(time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
